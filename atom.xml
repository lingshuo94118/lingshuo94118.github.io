<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>愿你眉目舒展</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-19T16:33:17.107Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>凌</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kafka-3:分区</title>
    <link href="http://example.com/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/"/>
    <id>http://example.com/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/</id>
    <published>2020-11-14T14:31:30.000Z</published>
    <updated>2021-09-19T16:33:17.107Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p> <img src="/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/1.png" alt="1"></p><p>分区，其实就是kafka的负载均衡方案，类似mongo的分片</p><p>不同分区放到不同机器节点，每节点独立执行格子分区请求，通过添加新的节点提升吞吐量</p><p>但是目前如果要保证消息的绝对顺序，就不能分区</p><p>但是对于不同的业务来说，不一定保证所有的消息都是顺序的， 只需要关联消息的顺序性，比如当前工作中送礼用户的id，原来工作中的单号</p><hr><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><ol><li><p>轮询：顺序分配，是 Kafka Java 生产者 API 默认提供的分区策略（未指定partitioner.class参数前提下），<strong>默认情况下它是最合理的分区策略</strong></p><p><img src="/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/2.png" alt="1"></p></li><li><p>随机：基本淘汰了</p></li><li><p>消息建：Key-ordering，简单来说就是根据 key进行hash放到对应分区，从而<strong>达到相同key（关联业务）放到一个分区，从而保证业务顺序性</strong>！！！！！！！！<br><img src="/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/3.png" alt="1"></p></li><li><p>地理位置分区</p></li></ol><p>总结：Java客户端默认的生产者分区策略的实现类为<code>org.apache.kafka.clients.producer.internals.DefaultPartitioner</code>。<br>默认策略为：<strong>如果指定了partition就直接发送到该分区；如果没有指定分区但是指定了key，就按照key的hash值选择分区；如果partition和key都没有指定就使用轮询策略</strong>。<br>而且如果key不为null，那么计算得到的分区号会是所有分区中的任意一个；如果key为null并且有可用分区时，那么计算得到的分区号仅为可用分区中的任意一个</p><hr><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ol><li>根据key分区有必要吗？具体案例？</li></ol><p>案例：之前做车辆实时定位(汽车每10s上传一次报文)显示的时候，发现地图显示车辆会突然退回去，开始排查怀疑是后端处理的逻辑问题导致的，但是后台保证了一台车只被一个线程处理，理论上不会出现这种情况；于是猜测是不是程序接收到消息的时候时间序就已经乱了，查阅了kafka相关资料，发现kafka同一个topic是无法保证数据的顺序性的，但是同一个partition中的数据是有顺序的；根据这个查看了接入端的代码(也就是kafka的生产者)，发现是按照kafka的默认分区策略(topic有10个分区，3个副本)发送的；于是将此处发送策略改为按照key(车辆VIN码)进行分区，后面车辆的定位显示就正常了。</p><ol start="2"><li>如果kafka搭了集群，有三个broker：123。这时候我对名称为test的topic发送消息，key设置为A，消息会随机发送到三个broker上去吗?</li></ol><p>会被发送到某个分区的leader副本上。这个分区的leader副本只能存在于3个broker中的一个，但是如果test的副本数是3，那么一条消息也会被备份到其他两个broker上。只是只有leader副本对外提供服务，因此没有顺序乱的情况出现。</p><ol start="3"><li>两个生产者，这时候消息如何确定消息的顺序呢?</li></ol><p>两个生产者生产的消息无法保证顺序，因为它们本身就没有前后之分，它们是并发的关系。除非业务处理</p><ol start="4"><li>一个生产者，发两次消息，但是网络原因，消息到达的顺序和消息发送的顺序不一致怎么办？</li></ol><p>设置max.in.flight.requests.per.connection=1来保证</p><ol start="5"><li>一台机器多个分区也会有负载均衡效果？也会提高吞吐量？</li></ol><p>通常1台broker上有多个分区依然能提升TPS，毕竟单个分区消耗不掉大部分的系统资源。</p><ol start="6"><li>key在哪指定，怎么指定啊</li></ol><p>Producer发送消息的时候可以直接指定key，比如producer.send(new ProducerRecord(“my-topic”, “key”, “value”));</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;分区&quot;&gt;&lt;a href=&quot;#分区&quot; class=&quot;headerlink&quot; title=&quot;分区&quot;&gt;&lt;/a&gt;分区&lt;/h2&gt;&lt;p&gt; &lt;img src=&quot;/2020/11/14/kafka-3-%E5%88%86%E5%8C%BA/1.png&quot; alt=&quot;1&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="kafka" scheme="http://example.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-2:集群配置参数</title>
    <link href="http://example.com/2020/10/29/kafka-2-%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
    <id>http://example.com/2020/10/29/kafka-2-%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</id>
    <published>2020-10-29T11:54:02.000Z</published>
    <updated>2021-09-19T16:31:58.578Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Broker-端参数"><a href="#Broker-端参数" class="headerlink" title="Broker 端参数"></a>Broker 端参数</h2><p>就是指的server.properties</p><ul><li><p><code>log.dirs</code>：指定了 <code>Broker</code> 需要使用的若干个文件目录路径（必须手动指定），<font color="red">生产环境中一定要为log.dirs配置多个路径</font>，例如<code>/home/kafka1,/home/kafka2,/home/kafka3</code>。最好挂载到不同的物理磁盘上—提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量 &amp;&amp; 实现故障转移：坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且 <code>Broker</code> 还能正常工作</p></li><li><p><code>listeners</code>：监听器，&lt;协议，主机名，端口&gt;，协议名比如 <code>PLAINTEXT</code> 表示明文传输、<code>SSL</code> 表示使用 <code>SSL</code> 或 <code>TLS</code> 加密传输等，自己定义的协议名字，比如<code>CONTROLLER: //localhost:9092</code>。必须还要指定<code>listener.security.protocol.map</code>参数告诉这个协议底层使用了哪种安全协议，比如指定<code>listener.security.protocol.map=CONTROLLER:PLAINTEXT</code>表示<code>CONTROLLER</code>这个自定义协议底层使用明文不加密传输数据。主机名，用ip也行，但用ip可能出现无法连接情况，</p></li><li><p>advertised.listeners：对外监听,主要是为外网访问用的。如果clients在内网环境访问Kafka不需要配置这个参数。<br>常见的玩法是：你的Kafka Broker机器上配置了双网卡，一块网卡用于内网访问（即我们常说的内网IP）；另一个块用于外网访问。那么你可以配置<code>listeners</code>为内网IP，<code>advertised.listeners</code>为外网IP。</p></li><li><p><code>auto.create.topics.enable</code>:是否允许自动生成topic,最好设置为false，不然代码写错了topic，就会自动生成错误的topic，管理混乱</p></li><li><p><code>unclean.leader.election.enable</code>:是否允许 Unclean Leader 选举,建议设置成false,比如当前分区leader副本挂了，同时几个数据比较多的追随者副本也挂了，只剩下一个一条数据的副本，要是让他当了leader会出现丢数据情况，所以宁可让这个分区失效，也不应该让他当领导。如果设置为true，就要做好丢数据的准备</p></li><li><p><code>auto.leader.rebalance.enable</code>：是否允许 Kafka 定期地对一些 Topic 分区进行 Leader 重选。建议false。参数<code>leader.imbalance.per.broker.percentage</code>控制触发比例，默认是10%。举个例子，如果一个broker上有10个分区，有2个分区的leader不是preferred leader，那么就会触发</p></li><li><p><code>message.max.bytes</code>:接受消息数据最大字节</p></li></ul><hr><h2 id="Topic-级别参数"><a href="#Topic-级别参数" class="headerlink" title="Topic 级别参数"></a>Topic 级别参数</h2><p>Topic 级别参数会覆盖全局 Broker 参数的值，而每个 Topic 都能设置自己的参数值，这就是所谓的 Topic 级别参数</p><p>例如Topic 根据自身业务需要，设置自己的留存时间，会覆盖broker的最长时间参数</p><ul><li><p>retention.ms ： 消息保存最长时间</p></li><li><p>retention.bytes： 可以使用多大磁盘空间，默认-1，无限使用磁盘空间</p></li><li><p>max.message.bytes：同broker一样</p></li></ul><p>使用参数创建实例：<br><code>bin/kafka-topics.sh--bootstrap-serverlocalhost:9092--create--topictransaction--partitions1--replication-factor1--configretention.ms=15552000000--configmax.message.bytes=5242880</code></p><p>修改示例：<br><code>bin/kafka-configs.sh--zookeeperlocalhost:2181--entity-typetopics--entity-nametransaction--alter--add-configmax.message.bytes=10485760</code></p><hr><h2 id="JVM-参数"><a href="#JVM-参数" class="headerlink" title="JVM 参数"></a>JVM 参数</h2><ul><li>如果 Broker 所在机器的 CPU 资源非常充裕，建议使用 CMS 收集器。启用方法是指定-XX:+UseCurrentMarkSweepGC。</li><li>使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC</li><li>已经在使用 Java 9 了，那么就用默认的 G1 收集器就好了。在没有任何调优的情况下，G1 表现得要比 CMS 出色，主要体现在更少的 Full GC，需要调整的参数更少等，所以使用 G1 就好了。</li></ul><p>注：需要再启动的时候指定</p><p>ulimit -n：随便往大了设置下，如果不设置，单机在Centos7上几百的并发就报“Too many open files”，如ulimit -n 1000000（任何一个 Java 项目最好都调整下这个值）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Broker-端参数&quot;&gt;&lt;a href=&quot;#Broker-端参数&quot; class=&quot;headerlink&quot; title=&quot;Broker 端参数&quot;&gt;&lt;/a&gt;Broker 端参数&lt;/h2&gt;&lt;p&gt;就是指的server.properties&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="kafka" scheme="http://example.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka-1:简介</title>
    <link href="http://example.com/2020/10/24/kafka-1-%E7%AE%80%E4%BB%8B/"/>
    <id>http://example.com/2020/10/24/kafka-1-%E7%AE%80%E4%BB%8B/</id>
    <published>2020-10-24T13:11:57.000Z</published>
    <updated>2021-09-19T15:58:00.064Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是kafka"><a href="#什么是kafka" class="headerlink" title="什么是kafka?"></a>什么是kafka?</h2><p>中间件？一个分布式流处理平台？消息队列？消息引擎系统？都是</p><h2 id="主题（Topic）"><a href="#主题（Topic）" class="headerlink" title="主题（Topic）"></a>主题（Topic）</h2><p>发布订阅的对象</p><p>每个业务、每个应用甚至是每类数据都创建专属的主题</p><p>向主题发布消息的客户端称为生产者<br>订阅主题消息的客户端应用程序就为消费者</p><p>一个 Kafka 集群由多个 <code>Broker</code> 组成，<code>Broker</code> 负责接收和处理客户端发送过来的请求，及对消息进行持久化。<br>常见的做法是将不同的 Broker 分散运行在不同的机器上，防止都在一台，服务器挂了就都废了</p><p>客户端 = 生产 + 消费<br>服务端 = <code>Broker</code> 服务进程， 一个 Kafka 集群由多个 <code>Broker</code> 组成</p><h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><p>相同的数据拷贝到多台机器上</p><p>领导者副本（Leader Replica）：对外提供服务<br>追随者副本（Follower Replica）：被动地追随领导者副本，<font color="red">不能与外界进行交互（不像mysql、redis等）</font>，向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步</p><ul><li>为什么不想mysql一样，追随者也可以对外提供读服务？</li></ul><p>如果允许follower副本对外提供读服务（主写从读），首先会存在<strong>数据一致性</strong>的问题，消息从主节点同步到从节点需要时间，可能造成主从节点的数据不一致。</p><p>主写从读无非就是为了减轻leader节点的压力，将读请求的负载均衡到follower节点，如果<strong>Kafka的分区相对均匀地分散到各个broker上，同样可以达到负载均衡的效果</strong></p><p>mysql一般部署在不同的机器上一台机器读写会遇到瓶颈，Kafka中的领导者副本一般均匀分布在不同的broker中，已经起到了负载的作用。即：同一个topic的已经通过分区的形式负载到不同的broker上了，读写的时候针对的领导者副本，但是量相比mysql一个还实例少太多，个人觉得没有必要在提供度读服务了。（如果量大还可以使用更多的副本，让每一个副本本身都不太大）</p><p>Kafka也<strong>不属于典型的读多写少场景</strong>，主从分离的优势不明显</p><ul><li>领导者副本积累了太多的数据，单台 Broker 机器都无法容纳怎么办？—伸缩性问题：分区</li></ul><h2 id="分区（Partition）"><a href="#分区（Partition）" class="headerlink" title="分区（Partition）"></a>分区（Partition）</h2><p>将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。<br>生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中。<br>（副本是在分区这个层级定义的。每个分区下可以配置 1领导 + n 追随）</p><p>生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始</p><p>多个分区多个领导者，实现负载。</p><p>但是目前kafka设计多个分区的话无法保证全局的消息顺序。如果一定要实现全局的消息顺序，只能单分区</p><p>1个主题有2个分区，消费者组有3个消费者：有一个消费者将无法分配到任何分区，处于idle状态</p><p> Kafka 的三层消息架构：</p><ul><li>第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。</li><li>第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。</li><li>第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。</li><li>最后，客户端程序只能与分区的领导者副本进行交互。</li></ul><hr><h2 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h2><p>分为点对点和发布订阅<br>点对点主要就是消费者组实现（group）<br>消费者组：多个消费者实例(进程、线程)共同组成一个组来消费一组主题,这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它<br>提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量<br>消费者组里面的所有消费者实例之间不但会竞争“消息资源”，还会彼此协作—重平衡（Rebalance）</p><p>重平衡（Rebalance）：组内某个实例挂掉了，Kafka自动检测到，把这个 Failed 实例之前负责的分区转移给其他活着的消费者</p><p>使用standalone consumer就完全避免rebalance了。事实上很多主流大数据流处理框架（Spark、Flink）都是这么使用的</p><h2 id="位移和消息位移"><a href="#位移和消息位移" class="headerlink" title="位移和消息位移"></a>位移和消息位移</h2><p>消费者位移（Consumer Offset）：每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上</p><p>位移（Offset）：每条消息在分区中的位置信息</p><p>区别：<br>“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了，针对的消息</p><p>“消费者位移”是随时变化的，毕竟它是消费者消费进度的指示器。另外每个消费者有着自己的消费者位移，消费完消息后使用一定策略更新自己的位移，针对的是消费者</p><p> <img src="/2020/10/24/kafka-1-%E7%AE%80%E4%BB%8B/1.png" alt="1"></p><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>消息日志保存数据，只能追加写，顺序I/O,不能随机I.O，保证了高吞吐量，<br>日志删除：为了避免日志堆积过多，提出日志段，旧的日志段写满了之后会再创建新的日志段，旧的日志段封存，定时任务扫描老的日志段是否能够删除</p><hr><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ul><li>mq和rpc调用的区别是什么呢?</li></ul><p>mq和rpc的区别往大了说属于数据流模式（dataflow mode）的问题。我们常见的数据流有三种：1. 通过数据库；2. 通过服务调用（REST/RPC）; 3. 通过异步消息传递（消息引擎，如Kafka）<br>RPC和MQ是有相似之处的，毕竟我们远程调用一个服务也可以看做是一个事件，但不同之处在于：</p><ol><li>MQ有自己的buffer，能够对抗过载（overloaded）和不可用场景</li><li>MQ支持重试</li><li>允许发布/订阅模式<br>当然它们还有其他区别。应该这样说RPC是介于通过数据库和通过MQ之间的数据流模式。</li></ol><ul><li>进程件通信的方式</li></ul><p>两个进程进行数据流交互的方式一般有三种：</p><ol><li>通过数据库：进程1写入数据库；进程2读取数据库（或者文件库）</li><li>通过服务调用：比如REST或RPC，而HTTP协议通常就作为REST方式的底层通讯协议</li><li>通过消息传递的方式：进程1发送消息给名为broker的中间件，然后进程2从该broker中读取消息。消息传输协议属于这种模式</li></ol><ul><li>为什么不直接通讯</li></ul><ol><li>削峰填谷：缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，保护了下游</li><li>下游服务多，需要都发送吗？费劲，降低耦合，易扩展</li></ol><ul><li>Kafka 提供高可用有哪些手段</li></ul><ol><li>Broker 分散运行在不同的机器上，某台服务器所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务</li><li>备份机制</li></ol><ul><li>java写的kafka为什么都是部署在linux上？</li></ul><ol><li>I/O: Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是 select,性能低</li><li>网络传输： Linux 部署 Kafka 能够享受到零拷贝技术所带来的快速数据传输特性。Windows 平台上必须要等到 Java 8 的 60 更新版本才行</li></ol><ul><li>需要固态硬盘吗？</li></ul><ol><li><p>多是顺序读写操作，一定程度上规避了机械磁盘最大的劣势，即随机读写操作慢。从这一点上来说，使用 SSD 似乎并没有太大的性能优势</p></li><li><p>使用磁盘阵列（RAID）：提供冗余的磁盘存储空间，提供负载均衡（但是kafka不太需要，自己就有高可用+负载均衡，有钱随便）</p><p><img src="/2020/10/24/kafka-1-%E7%AE%80%E4%BB%8B/1.png" alt="1"></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是kafka&quot;&gt;&lt;a href=&quot;#什么是kafka&quot; class=&quot;headerlink&quot; title=&quot;什么是kafka?&quot;&gt;&lt;/a&gt;什么是kafka?&lt;/h2&gt;&lt;p&gt;中间件？一个分布式流处理平台？消息队列？消息引擎系统？都是&lt;/p&gt;
&lt;h2 id=&quot;主题</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="kafka" scheme="http://example.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>redis13-慢redis总结</title>
    <link href="http://example.com/2020/10/14/redis13-%E6%85%A2redis%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2020/10/14/redis13-%E6%85%A2redis%E6%80%BB%E7%BB%93/</id>
    <published>2020-10-14T11:34:32.000Z</published>
    <updated>2021-09-14T08:12:43.737Z</updated>
    
    <content type="html"><![CDATA[<h1 id="慢redis总结"><a href="#慢redis总结" class="headerlink" title="慢redis总结"></a>慢redis总结</h1><h2 id="判断是否真的慢"><a href="#判断是否真的慢" class="headerlink" title="判断是否真的慢"></a>判断是否真的慢</h2><p>通过链路追踪，redis出入口的响应延时定位是否为redis服务延时长<br>排查是否为网络问题，是否有丢包的现象<br>最终进行性能测试</p><p>基准性能：不同机器性能不同，但是一样的服务器配置，有个实例明显比其他通配置实例慢，那就应该有问题</p><ul><li>查看60秒内最大延时：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60</span><br><span class="line">Max latency so far: 32 microseconds.</span><br><span class="line">Max latency so far: 59 microseconds.</span><br><span class="line">Max latency so far: 72 microseconds.</span><br></pre></td></tr></table></figure><p>结果60秒内最大延时72毫秒</p><ul><li>一段时间内 Redis 的最小、最大、平均访问延迟</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1</span><br><span class="line">min: 0, max: 1, avg: 0.13 (100 samples) -- 1.01 seconds range</span><br><span class="line">min: 0, max: 1, avg: 0.12 (99 samples) -- 1.01 seconds range</span><br><span class="line">min: 0, max: 1, avg: 0.13 (99 samples) -- 1.01 seconds range</span><br><span class="line">min: 0, max: 1, avg: 0.10 (99 samples) -- 1.01 seconds range</span><br></pre></td></tr></table></figure><p>结果每间隔 1 秒，采样 Redis 的平均操作耗时，其结果分布在 0.08 ~ 0.13 毫秒之间</p><p>找一个正常的和你觉得慢的对比下上面这些参数，如果差距明显就确诊了，确诊后进一步确定问题原因</p><h2 id="高复杂度命令"><a href="#高复杂度命令" class="headerlink" title="高复杂度命令"></a>高复杂度命令</h2><p>根据redis慢日志（slowlog），查看只是时间长的命令</p><ul><li>慢日志阈值等配置：<br>eg：阈值5 毫秒，最近 500 条</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONFIG SET slowlog-log-slower-than 5000</span><br><span class="line">CONFIG SET slowlog-max-len 500</span><br></pre></td></tr></table></figure><ul><li>查询慢日志：SLOWLOG get 5</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SLOWLOG get 5</span><br><span class="line">1) 1) (integer) 32693       # 慢日志ID</span><br><span class="line">   2) (integer) 1593763337  # 执行时间戳</span><br><span class="line">   3) (integer) 5299        # 执行耗时(微秒)</span><br><span class="line">   4) 1) &quot;LRANGE&quot;           # 具体执行的命令和参数</span><br><span class="line">      2) &quot;user_list:2000&quot;</span><br><span class="line">      3) &quot;0&quot;</span><br><span class="line">      4) &quot;-1&quot;</span><br><span class="line">2) 1) (integer) 32692</span><br><span class="line">   2) (integer) 1593763337</span><br><span class="line">   3) (integer) 5044</span><br><span class="line">   4) 1) &quot;GET&quot;</span><br><span class="line">      2) &quot;user_info:1000&quot;...</span><br></pre></td></tr></table></figure><ul><li>常见的慢命令</li></ul><h2 id="bigkey"><a href="#bigkey" class="headerlink" title="bigkey"></a>bigkey</h2><h2 id="集中过期"><a href="#集中过期" class="headerlink" title="集中过期"></a>集中过期</h2><h2 id="内存上限"><a href="#内存上限" class="headerlink" title="内存上限"></a>内存上限</h2><h2 id="fork进程"><a href="#fork进程" class="headerlink" title="fork进程"></a>fork进程</h2><h2 id="内存大页"><a href="#内存大页" class="headerlink" title="内存大页"></a>内存大页</h2><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><h2 id="绑定cpu"><a href="#绑定cpu" class="headerlink" title="绑定cpu"></a>绑定cpu</h2><h2 id="swap"><a href="#swap" class="headerlink" title="swap"></a>swap</h2><h2 id="碎片整理"><a href="#碎片整理" class="headerlink" title="碎片整理"></a>碎片整理</h2><h2 id="网络带宽"><a href="#网络带宽" class="headerlink" title="网络带宽"></a>网络带宽</h2><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;慢redis总结&quot;&gt;&lt;a href=&quot;#慢redis总结&quot; class=&quot;headerlink&quot; title=&quot;慢redis总结&quot;&gt;&lt;/a&gt;慢redis总结&lt;/h1&gt;&lt;h2 id=&quot;判断是否真的慢&quot;&gt;&lt;a href=&quot;#判断是否真的慢&quot; class=&quot;header</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis12-阻塞总结</title>
    <link href="http://example.com/2020/09/29/redis12-%E9%98%BB%E5%A1%9E%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2020/09/29/redis12-%E9%98%BB%E5%A1%9E%E6%80%BB%E7%BB%93/</id>
    <published>2020-09-29T06:02:53.000Z</published>
    <updated>2021-09-14T08:10:38.531Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis阻塞"><a href="#redis阻塞" class="headerlink" title="redis阻塞"></a>redis阻塞</h1><p>客户端：网络 IO，键值对增删改查操作，数据库操作<br>磁盘：生成 RDB 快照，记录 AOF 日志，AOF 日志重写<br>主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件<br>切片集群实例：向其他实例传输哈希槽信息，数据迁移</p><p><img src="/2020/09/29/redis12-%E9%98%BB%E5%A1%9E%E6%80%BB%E7%BB%93/18.jpg" alt="导入"></p><h2 id="客户端交互"><a href="#客户端交互" class="headerlink" title="客户端交互"></a>客户端交互</h2><p>网络IO不是主要因素：redis使用IO多路复用，避免主线程一直等待网络连接</p><p>复杂度高的键值对增删改查：O(N)，例如集合全量查询和聚合操作，bigKey删除<br><img src="/2020/09/29/redis12-%E9%98%BB%E5%A1%9E%E6%80%BB%E7%BB%93/19.jpg" alt="导入"></p><ol><li>当元素数量从 10 万增加到 100 万时，4 大集合类型的删除时间的增长幅度从 5 倍上升到了近 20 倍；</li><li>集合元素越大，删除所花费的时间就越长；</li><li>当删除有 100 万个元素的集合时，最大的删除时间接近2秒！！！（Hash 类型）。Redis 的响应时间一般在微秒级别，所以。。</li></ol><h2 id="磁盘交互"><a href="#磁盘交互" class="headerlink" title="磁盘交互"></a>磁盘交互</h2><p>AOF写回策略如果是always。。。。<strong>写回是主线程，重写是子线程</strong></p><p>一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话…</p><p>虽然子进程的方式生成 RDB 快照文件，以及执行 AOF 日志重写操作。慢速的磁盘 IO 就不会阻塞主线程了。<br>但是fork这个瞬间一定是会阻塞主线程的</p><h2 id="主从交互"><a href="#主从交互" class="headerlink" title="主从交互"></a>主从交互</h2><p>从库在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库（更大的删除bigkey操作）<br>从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢–阻塞</p><h2 id="切片集群实例交互"><a href="#切片集群实例交互" class="headerlink" title="切片集群实例交互"></a>切片集群实例交互</h2><p>每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。<br>如果你使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。<br>只需要知道，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>五个阻塞点：集合全量查询和聚合操作；bigkey 删除；清空数据库；AOF 日志同步写；从库加载 RDB 文件</p><p>这五个可以异步操作吗？<br>集合全量查询和聚合操作              从库加载 RDB 文件      不可以 剩下的都可以</p><h2 id="redis异步子线程机制"><a href="#redis异步子线程机制" class="headerlink" title="redis异步子线程机制"></a>redis异步子线程机制</h2><p>主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，<strong>分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行</strong>。</p><p><strong>主线程通过一个链表形式的任务队列和子线程进行交互</strong>。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。</p><p>等到后台子线程从任务队列中读取任务后，开始删除并释放内存空间。—-<strong>惰性删除</strong>（lazy free）。删除或清空操作不会阻塞主线程</p><p>当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。</p><p><img src="/2020/09/29/redis12-%E9%98%BB%E5%A1%9E%E6%80%BB%E7%BB%93/20.jpg" alt="导入"></p><p>异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">FLUSHDB ASYNC</span><br><span class="line">FLUSHALL AYSNC</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redis阻塞&quot;&gt;&lt;a href=&quot;#redis阻塞&quot; class=&quot;headerlink&quot; title=&quot;redis阻塞&quot;&gt;&lt;/a&gt;redis阻塞&lt;/h1&gt;&lt;p&gt;客户端：网络 IO，键值对增删改查操作，数据库操作&lt;br&gt;磁盘：生成 RDB 快照，记录 AOF 日</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis11-和cpu的关系</title>
    <link href="http://example.com/2020/09/26/redis11-%E5%92%8Ccpu%E7%9A%84%E5%85%B3%E7%B3%BB/"/>
    <id>http://example.com/2020/09/26/redis11-%E5%92%8Ccpu%E7%9A%84%E5%85%B3%E7%B3%BB/</id>
    <published>2020-09-26T11:08:12.000Z</published>
    <updated>2021-09-14T08:10:06.346Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cpu对redis的影响"><a href="#cpu对redis的影响" class="headerlink" title="cpu对redis的影响"></a>cpu对redis的影响</h1><p>cpu颗数:<code>cat /proc/cpuinfo | grep &#39;physical id&#39; | sort | uniq | wc -l</code><br>cpu物理核数：<code>cat /proc/cpuinfo |grep &quot;cores&quot;|uniq|awk &#39;&#123;print $4&#125;&#39;</code><br>cpu逻辑核数：<code>cat /proc/cpuinfo |grep &quot;processor&quot;|wc -l</code>   ps:生产单颗、4物理、8逻辑<br>或者直接<code>lscpu</code>能查看全部信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Architecture:          x86_64 #架构</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                8 #逻辑cpu</span><br><span class="line">On-line CPU(s) list:   0-7</span><br><span class="line">Thread(s) per core:    2 #每个物理核超线程数（逻辑核）</span><br><span class="line">Core(s) per socket:    4 #cpu插槽数（物理核）</span><br><span class="line">Socket(s):             1 #物理cpu（插槽数）</span><br><span class="line">NUMA node(s):          1</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               3000.000</span><br><span class="line">BogoMIPS:              6000.00</span><br><span class="line">Hypervisor vendor:     KVM</span><br><span class="line">Virtualization type:   full</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K #二级缓存</span><br><span class="line">L3 cache:              25344K #三级缓存</span><br><span class="line">NUMA node0 CPU(s):     0-7</span><br><span class="line">Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 ida arat pku ospke</span><br></pre></td></tr></table></figure><h2 id="主流的-CPU-架构"><a href="#主流的-CPU-架构" class="headerlink" title="主流的 CPU 架构"></a>主流的 CPU 架构</h2><p>cpu多核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。</p><p>所以，当数据或指令保存在 L1、L2 缓存时，物理核访问它们的延迟不超过 10 纳秒</p><p>L1 和 L2 缓存的大小受限于处理器的制造技术，一般只有 KB 级别</p><p>如果 L1、L2 缓存中没有所需的数据，需要访问内存来获取数据。比一、二级缓存慢了近10倍</p><p>不同的物理核还会共享一个共同的三级缓存，L3 一般比较大，能达到几 MB 到几十 MB</p><p>当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。</p><p>主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。</p><p> <img src="/2020/09/26/redis11-%E5%92%8Ccpu%E7%9A%84%E5%85%B3%E7%B3%BB/cpu%E6%A0%B8.png" alt="1"></p><p> 在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。</p><p>如图：多颗cpu的服务器</p><p> <img src="/2020/09/26/redis11-%E5%92%8Ccpu%E7%9A%84%E5%85%B3%E7%B3%BB/%E5%A4%9A%E9%A2%97cpu.png" alt="1"></p><p>多 CPU 架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。<br>属于<strong>远端内存访问</strong>。和访问 Socket 直接连接的内存相比，<strong>远端内存访问会增加应用程序的延迟</strong>。</p><h2 id="CPU-多核对-Redis-性能的影响"><a href="#CPU-多核对-Redis-性能的影响" class="headerlink" title="CPU 多核对 Redis 性能的影响"></a>CPU 多核对 Redis 性能的影响</h2><p>在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU 核的寄存器值等），我们把这些信息称为运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到 L1、L2 缓存上，以便提升执行速度。<br>但是，在多核 CPU 的场景下，一旦应用程序需要在一个新的 CPU 核上运行，那么，运行时信息就需要重新加载到新的 CPU 核上。而且，新的 CPU 核的 L1、L2 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。</p><p>context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。<br>当 context switch 发生后，Redis 主线程的运行时信息需要被重新加载到另一个 CPU 核上，而且，此时，另一个 CPU 核上的 L1、L2 缓存中，并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。</p><p>这个重新加载的过程是需要花费一定时间的。而且，Redis 实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。<br>如果在 CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。<br>每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。<br>所以，我们要避免 Redis 总是在不同 CPU 核上来回调度执行。<br>尝试着把 Redis 实例和 CPU 核绑定，让一个 Redis 实例固定运行在一个 CPU 核上。我们可以使用 taskset 命令把一个程序绑定在一个核上运行。比如说，我们执行下面的命令，就把 Redis 实例绑在了 0 号核上，其中，“-c”选项用于设置要绑定的核编号。</p><p><code>taskset -c 0 ./redis-server</code></p><p>当然，绑核不仅对降低尾延迟有好处，同样也能降低平均延迟、提升吞吐率，进而提升 Redis 性能。接下来，我们再来看看多 CPU 架构，也就是 NUMA 架构，对 Redis 性能的影响。</p><h2 id="NUMA-架构对-Redis-性能的影响"><a href="#NUMA-架构对-Redis-性能的影响" class="headerlink" title="NUMA 架构对 Redis 性能的影响"></a>NUMA 架构对 Redis 性能的影响</h2><p>经常看到一种做法，为了提升 Redis 的网络性能，把操作系统的<strong>网络中断处理程序</strong>和 CPU 核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。</p><p>先来看下 Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件，通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间</p><p>在 CPU 的 NUMA 架构下，当网络中断处理程序、Redis 实例分别和 CPU 核绑定后，就会有一个潜在的风险：<strong>如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，那么，Redis 实例读取网络数据时，就需要跨 CPU Socket 访问内存</strong>，这个过程会花费较多时间。</p><p> <img src="/2020/09/26/redis11-%E5%92%8Ccpu%E7%9A%84%E5%85%B3%E7%B3%BB/redis%E5%92%8C%E4%B8%AD%E6%96%AD%E7%A8%8B%E5%BA%8F%E8%B7%A8cpu.png" alt="1"></p><p>跨 CPU Socket 的内存访问延迟增加了 18%，这自然会导致 Redis 处理请求的延迟增加</p><p>在 CPU 多核的场景下，用 taskset 命令把 Redis 实例和一个核绑定，可以减少 Redis 实例在不同核上被来回调度执行的开销，避免较高的尾延迟；在多 CPU 的 NUMA 架构下，如果你对网络中断程序做了绑核操作，建议你同时把 Redis 实例和网络中断程序绑在同一个 CPU Socket 的不同核上，这样可以避免 Redis 跨 Socket 访问内存中的网络数据的时间开销（注意：<strong>NUMA 架构下 CPU 核的编号方法，这样才不会绑错核</strong>。）</p><h2 id="绑核的风险"><a href="#绑核的风险" class="headerlink" title="绑核的风险"></a>绑核的风险</h2><p>Redis 除了主线程以外，还有用于 RDB 生成和 AOF 重写的子进程还有Redis 的后台线程 会和主线程 竞争 CPU 资源</p><p>一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加</p><p>解决方法：</p><ol><li><p>一个 Redis 实例对应绑一个物理核，而不是逻辑核<br><code>taskset -c 0,1 ./redis-server</code><br>和只绑一个逻辑核相比，把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。</p></li><li><p>优化 Redis 源码</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;cpu对redis的影响&quot;&gt;&lt;a href=&quot;#cpu对redis的影响&quot; class=&quot;headerlink&quot; title=&quot;cpu对redis的影响&quot;&gt;&lt;/a&gt;cpu对redis的影响&lt;/h1&gt;&lt;p&gt;cpu颗数:&lt;code&gt;cat /proc/cpuinfo </summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis9-消息队列</title>
    <link href="http://example.com/2020/09/25/redis9-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://example.com/2020/09/25/redis9-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2020-09-25T14:01:08.000Z</published>
    <updated>2021-09-14T08:08:28.782Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis消息队列"><a href="#redis消息队列" class="headerlink" title="redis消息队列"></a>redis消息队列</h1><h2 id="基于list"><a href="#基于list" class="headerlink" title="基于list"></a>基于list</h2><p>最常见生产者先用 LPUSH 写入了两条库存消息，分别是 5 和 3，表示要把库存更新为 5 和 3；消费者则用 RPOP 把两条消息依次读出</p><ul><li>风险一：List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令（比如while(1) 循环）。<br>如果有新消息写入，RPOP 命令就会返回结果，否则，RPOP 命令返回空值，再继续循环。<strong>CPU 一直消耗在执行 RPOP 命令上</strong></li></ul><p><strong>BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong></p><ul><li><p>风险二：redis如何保证重复消费<br>虽然redis单线程，pop都是原子性操作，但是因为业务等原因，还是要做重复判断，防止重复消费<br>比如每个消息添加一个全局id保证唯一，消费者收到了之后再判断下这个id是否已经消费过了</p></li><li><p>风险三：如何保证宕机消息不丢失<br>持久化的基础上<strong>使用List 类型提供的</strong> <code>BRPOPLPUSH</code> <strong>命令</strong></p></li></ul><p>作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。<br><strong>消费者成功消费取出的消息后，最好把备份队列中的消息删除，防止备份队列存储过多无用的数据，导致内存浪费。</strong></p><ul><li>风险四：生产消费能力不匹配，导致list内存积压<br>只能使用多线程不支持消费组</li></ul><h2 id="Streams-数据类型"><a href="#Streams-数据类型" class="headerlink" title="Streams 数据类型"></a>Streams 数据类型</h2><p>redis5.0之后的版本提供，专门实现消息队列的数据类型<br>命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">XADD：插入消息，保证有序，可以自动生成全局唯一 ID；</span><br><span class="line">XREAD：用于读取消息，可以按 ID 读取数据；</span><br><span class="line">XREADGROUP：按消费组形式读取消息；</span><br><span class="line">XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</span><br><span class="line">&#96;&#96;&#96;&#96;</span><br><span class="line"></span><br><span class="line">注：</span><br><span class="line">xadd可以自动生成全局唯一 ID；</span><br><span class="line">XRAED可以指定从某个id之后开始读取，也能指定block配置，实现阻塞读取</span><br><span class="line">命令最后的“$”符号表示读取最新的消息，同时，我们设置了 block 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。下面命令中的 XREAD 执行后，消息队列 mqstream 中一直没有消息，所以，XREAD 在 10 秒后返回空值（nil）。</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;code</span><br><span class="line">XREAD block 10000 streams mqstream $</span><br></pre></td></tr></table></figure><p>Streams则是采用ack的方式，保证消息成功消费</p><p><img src="/2020/09/25/redis9-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/17.jpg" alt="导入"></p><p>起始还有redis的pub、sub发布订阅，但是已经基本淘汰了，除了哨兵用<br>因为消息不可靠，不能持久化（ Pub/Sub 没有基于任何数据类型实现），宕机无法恢复<br>消息积压就会强制消费者下线（消费者下线消息就直接丢了）</p><p>总结：但是终究不是专业的消息中间件<br>Redis 在以下 2 个场景下，都会导致数据丢失：</p><ol><li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li><li>主从复制也是异步的，主从切换时，也存在丢失数据的可能（从库还未同步完成主库发来的数据，就被提成主库）</li></ol><p>还有：面对消息积压，Redis 内存资源紧张，一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。但 Kafka、RabbitMQ 这类消息队列就不一样了，它们的数据都会存储在磁盘上</p><p>适用场景：不是绝对一致，且体量小的业务</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redis消息队列&quot;&gt;&lt;a href=&quot;#redis消息队列&quot; class=&quot;headerlink&quot; title=&quot;redis消息队列&quot;&gt;&lt;/a&gt;redis消息队列&lt;/h1&gt;&lt;h2 id=&quot;基于list&quot;&gt;&lt;a href=&quot;#基于list&quot; class=&quot;head</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis10-内存碎片</title>
    <link href="http://example.com/2020/09/25/redis10-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/"/>
    <id>http://example.com/2020/09/25/redis10-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/</id>
    <published>2020-09-25T13:49:12.000Z</published>
    <updated>2021-09-14T08:04:34.491Z</updated>
    
    <content type="html"><![CDATA[<h1 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h1><p>Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc</p><p>jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。</p><p>判断内存碎片</p><p><code>INFO memory</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">used_memory:1073741736</span><br><span class="line">used_memory_human:1024.00M</span><br><span class="line">used_memory_rss:1997159792</span><br><span class="line">used_memory_rss_human:1.86G</span><br><span class="line">…</span><br><span class="line">mem_fragmentation_ratio:1.86</span><br></pre></td></tr></table></figure><p><code>mem_fragmentation_ratio = used_memory_rss/ used_memory</code></p><p>used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；而 used_memory 是 Redis 为了保存数据实际申请使用的空间。</p><p>经验阈值：<br>mem_fragmentation_ratio 大于 1 但小于 1.5。合理。内存分配器是一定要使用的，分配策略都是通用的。mem_fragmentation_ratio 大于 1.5 。内存碎片率已经超过了 50%。一般情况下需要采取一些措施来降低内存碎片率了。</p><p>如何清理内存碎片？</p><ol><li>重启：代价太大</li><li>4.0后可配置自动清理：类似jvm的复制算法不过不需要分成两块空间</li></ol><p>Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，命令如下：</p><p><code>config set activedefrag yes</code></p><p>两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。<br><code>active-defrag-ignore-bytes 100mb</code></p><p>表示内存碎片的字节数达到 100MB 时，开始清理</p><p><code>active-defrag-threshold-lower 10</code></p><p>表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理</p><p>为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。</p><p><code>active-defrag-cycle-min 25</code><br>表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；</p><p><code>active-defrag-cycle-max 75</code><br>表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;内存碎片&quot;&gt;&lt;a href=&quot;#内存碎片&quot; class=&quot;headerlink&quot; title=&quot;内存碎片&quot;&gt;&lt;/a&gt;内存碎片&lt;/h1&gt;&lt;p&gt;Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc&lt;/</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis8-统计，三种扩展数据类型</title>
    <link href="http://example.com/2020/09/22/redis8-%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%B8%89%E7%A7%8D%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>http://example.com/2020/09/22/redis8-%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%B8%89%E7%A7%8D%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</id>
    <published>2020-09-22T03:59:54.000Z</published>
    <updated>2021-09-14T08:08:30.270Z</updated>
    
    <content type="html"><![CDATA[<h1 id="统计，三种扩展数据类型"><a href="#统计，三种扩展数据类型" class="headerlink" title="统计，三种扩展数据类型"></a>统计，三种扩展数据类型</h1><h2 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h2><p>交集<br>并集<br>差集</p><p>例如<br>统计手机 App 每天的新增用户数和第二天的留存用户数<br>key : userid  记录所有用户uid<br>key : userid20210604 记录20210604登陆的用户</p><p>差集：计算20210604新增的用户，并放到新的set usernew 里面<br><code>SDIFFSTORE usernew userid20210604 userid</code><br>并集：新增用户加到所有用户里面<br><code>SUNIONSTORE userid userid userid20210604</code><br>交集：计算0603和0604都登陆的用户<br><code>SINTERSTORE useridRem userid20210603 userid20210604</code><br><strong>对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择</strong></p><h3 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h3><p>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p><h2 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h2><p>list和zset都能排序，但是一般用zset<br>比如用list排序，分页的话第一页展示完，请求第二页时插入了新的数据，第二页就会出现第一页展示过的数据，zset可以根据权重排序</p><h2 id="二值状态统计Bitmap"><a href="#二值状态统计Bitmap" class="headerlink" title="二值状态统计Bitmap"></a>二值状态统计Bitmap</h2><p>记录签到（1）或未签到（0）</p><p>奖励发放（1）或未发放（0）</p><p><strong>Bitmap</strong><br>Bitmap 提供了 GETBIT/SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写（从0开始）<br>BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。<br>列如记录id为3000的用户在8月3号签到信息<br>key : uidsign3000:202008        offset : 2<br><code>SETBIT uidsign3000:202008 2 1</code><br>检查该用户 8 月 3 日是否签到<br><code>GETBIT uid:sign:3000:202008 2</code><br>统计该用户在 8 月份的签到次数。<br><code>BITCOUNT uid:sign:3000:202008</code></p><p>Bitmap 支持用 BITOP 命令对多个 Bitmap 按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的 Bitmap 中<br><img src="/2020/09/22/redis8-%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%B8%89%E7%A7%8D%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/15.jpg" alt="导入"><br>例如统计1亿用户连续十天签到情况<br>可以日期为key 对应的uid签到的设置为1<br>十个key取<strong>与</strong>操作，放到新的bitmap里面，新的对应是1的才是10天都签到的<br>然后bitcount就是签到总数</p><p>1 个 1 亿位的 Bitmap，大约占 12MB</p><h2 id="基数统计HyperLogLog"><a href="#基数统计HyperLogLog" class="headerlink" title="基数统计HyperLogLog"></a>基数统计HyperLogLog</h2><p>比如多少人完成了活动<br>多少人访问了页面</p><p>可以用zset去重添加用户id，最后zcard或者hash，判断存在不存在不存在再添加，最后再HLEN<br>但是活动时每天的数据统计，或者页面几百几千万<br>太费内存了</p><p>HyperLogLog<br>每个 HyperLogLog 只需要花费 12 KB 内存<br>可以计算接近 2^64 个元素的基数<br>key ：page1Uv<br><code>PFADD page1Uv uid1 uid2 uid3 uid4 uid5 uid1 uid1 uid1 uid1 uid1 uid1 uid1 uid1 uid1</code><br>PFCOUNT 命令直接获得基数<br><code>pfcount page1Uv</code><br>如上输出5</p><p><strong>HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</strong><br><img src="/2020/09/22/redis8-%E7%BB%9F%E8%AE%A1%EF%BC%8C%E4%B8%89%E7%A7%8D%E6%89%A9%E5%B1%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/16.jpg" alt="导入"></p><h2 id="GEO经纬度"><a href="#GEO经纬度" class="headerlink" title="GEO经纬度"></a>GEO经纬度</h2><p>每个车对应一个经纬度<br>如果用hash，存储所有车辆位置信息，可实现<br>但是如果用户搜索附近的车，不支持根据经纬度范围查询（hashcode随机）</p><p>如果用zset，socre有范围</p><p>GEO:底层用zset，根据GEOHash编码（就是分别对经纬度左右二分法，左1，又0，分别将经纬度转换成1001111这种类型的数据，然后，偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，合到一起）<br>将经纬度信息变成10组合形成的score分数<br>eg：存33号车经纬度<br><code>GEOADD carsInfo 116.034579 39.030452 33</code><br>eg:根据用户经纬度查找5公里范围的10个车<br><code>GEORADIUS carsInfo 116.054579 39.030452 5 km ASC COUNT 10</code><br><a href="https://time.geekbang.org/column/article/281745">https://time.geekbang.org/column/article/281745</a></p><h2 id="redis数据类型扩展"><a href="#redis数据类型扩展" class="headerlink" title="redis数据类型扩展"></a>redis数据类型扩展</h2><p>基于Redis实现的布隆过滤器，其底层实现利用的是String数据结构和位运算，可以解决业务层缓存穿透的问题，而且内存占用非常小，操作非常高效。</p><p>Redis提供的PubSub，可以支持多个消费者进行消费，生产者发布一条消息，多个消费者同时订阅消费。但是它的缺点是，如果任意一个消费者挂了，等恢复过来后，在这期间的生产者的数据就丢失了。PubSub只把数据发给在线的消费者，消费者一旦下线，就会丢弃数据。另一个缺点是，PubSub中的数据不支持数据持久化，当Redis宕机恢复后，其他类型的数据都可以从RDB和AOF中恢复回来，但PubSub不行，它就是简单的基于内存的多播机制。</p><p>Redis 5.0推出了Stream数据结构，它借鉴了Kafka的设计思想，弥补了List和PubSub的不足。Stream类型数据可以持久化、支持ack机制、支持多个消费者、支持回溯消费，基本上实现了队列中间件大部分功能，比List和PubSub更可靠。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;统计，三种扩展数据类型&quot;&gt;&lt;a href=&quot;#统计，三种扩展数据类型&quot; class=&quot;headerlink&quot; title=&quot;统计，三种扩展数据类型&quot;&gt;&lt;/a&gt;统计，三种扩展数据类型&lt;/h1&gt;&lt;h2 id=&quot;聚合统计&quot;&gt;&lt;a href=&quot;#聚合统计&quot; class=&quot;</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis7-省内存</title>
    <link href="http://example.com/2020/09/18/redis7-%E7%9C%81%E5%86%85%E5%AD%98/"/>
    <id>http://example.com/2020/09/18/redis7-%E7%9C%81%E5%86%85%E5%AD%98/</id>
    <published>2020-09-18T13:11:09.000Z</published>
    <updated>2021-09-14T08:08:32.708Z</updated>
    
    <content type="html"><![CDATA[<h1 id="省内存"><a href="#省内存" class="headerlink" title="省内存"></a>省内存</h1><h2 id="为什么-String-类型内存开销大？"><a href="#为什么-String-类型内存开销大？" class="headerlink" title="为什么 String 类型内存开销大？"></a>为什么 String 类型内存开销大？</h2><p>photo_id: 1101000051<br>photo_obj_id: 3301000051<br>我们保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。<br>但问题是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。</p><p>除了记录实际数据，<strong>String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据</strong>。<strong>当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。</strong></p><h3 id="String-类型具体是怎么保存数据"><a href="#String-类型具体是怎么保存数据" class="headerlink" title="String 类型具体是怎么保存数据"></a>String 类型具体是怎么保存数据</h3><p>当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。<br>但是<br><strong>当你保存的数据中包含字符时，String 类型就会用简单动态字符串</strong>（Simple Dynamic String，SDS）结构体来保存<br><img src="/2020/09/18/redis7-%E7%9C%81%E5%86%85%E5%AD%98/13.jpg" alt="导入"></p><p>buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。<br>len：占 4 个字节，表示 buf 的已用长度。<br>alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。</p><p>对于 String 类型来说，<strong>除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销。</strong></p><p>因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。</p><p>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在</p><p>Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。<br>一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。<br><strong>另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。</strong></p><p><strong>当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</strong><br><img src="/2020/09/18/redis7-%E7%9C%81%E5%86%85%E5%AD%98/14.jpg" alt="导入"></p><p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节,还少32个字节<br>Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。<br>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p><h2 id="用什么数据结构可以节省内存"><a href="#用什么数据结构可以节省内存" class="headerlink" title="用什么数据结构可以节省内存"></a>用什么数据结构可以节省内存</h2><p>压缩列表<br>头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。<br>它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。</p><ul><li>prev_len：表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。</li><li>len：表示自身长度，4 字节；</li><li>encoding：表示编码方式，1 字节；</li><li>content：保存实际数据。<br>entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接<br>一个图片存储对象 ID（8 字节），此时，每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8=14），实际分配 16 字节。<br>Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。</li></ul><h2 id="如何用集合类型保存单值的键值对？"><a href="#如何用集合类型保存单值的键值对？" class="headerlink" title="如何用集合类型保存单值的键值对？"></a>如何用集合类型保存单值的键值对？</h2><p>基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value</p><p>以图片 ID 1101000060<br>图片存储对象 ID 3302000080 为例，<br>我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。<br>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。</p><p><code>hset 1101000 060 3302000080</code></p><p>这样以1101000开头的1000个id用一个key ，但是hash的key不同</p><p>Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash 类型设置了用压缩列表保存数据时的两个阈值</p><p><code>hash-max-ziplist-entries</code>：表示用压缩列表保存时哈希集合中的最大元素个数。<br><code>hash-max-ziplist-value</code>：表示用压缩列表保存时哈希集合中单个元素的最大长度。</p><p>如果我们往 Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。</p><p>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了</p><p>保存图片的例子，除了用String和Hash存储之外，还可以用Sorted Set存储（勉强）。</p><p>Sorted Set与Hash类似，当元素数量少于zset-max-ziplist-entries，并且每个元素内存占用小于zset-max-ziplist-value时，默认也采用ziplist结构存储。我们可以把zset-max-ziplist-entries参数设置为1000，这样Sorted Set默认就会使用ziplist存储了，member和score也会紧凑排列存储，可以节省内存空间。</p><p>使用zadd 1101000 3302000080 060命令存储图片ID和对象ID的映射关系，查询时使用zscore 1101000 060获取结果。</p><p>但是Sorted Set使用ziplist存储时的缺点是，这个ziplist是需要按照score排序的（为了方便zrange和zrevrange命令的使用），所以在插入一个元素时，需要先根据score找到对应的位置，然后把member和score插入进去，这也意味着Sorted Set插入元素的性能没有Hash高（这也是前面说勉强能用Sorte Set存储的原因）。而Hash在插入元素时，只需要将新的元素插入到ziplist的尾部即可，不需要定位到指定位置。</p><p>不管是使用Hash还是Sorted Set，当采用ziplist方式存储时，虽然可以节省内存空间，但是在查询指定元素时，都要遍历整个ziplist，找到指定的元素。所以使用ziplist方式存储时，虽然可以利用CPU高速缓存，但也不适合存储过多的数据</p><p>当使用ziplist存储时，我们尽量存储int数据，ziplist在设计时每个entry都进行了优化，针对要存储的数据，会尽量选择占用内存小的方式存储（整数比字符串在存储时占用内存更小），这也有利于我们节省Redis的内存。还有，因为ziplist是每个元素紧凑排列，而且每个元素存储了上一个元素的长度，所以当修改其中一个元素超过一定大小时，会引发多个元素的级联调整（前面一个元素发生大的变动，后面的元素都要重新排列位置，重新分配内存），这也会引发性能问题，需要注意。</p><p>另外，使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难（无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂）。而使用String虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。</p><p>所以在选用Hash和Sorted Set存储时，意味着把Redis当做数据库使用，这样就需要务必保证Redis的可靠性（做好备份、主从副本），防止实例宕机引发数据丢失的风险。而采用String存储时，可以把Redis当做缓存使用，每个key设置过期时间，同时设置maxmemory和淘汰策略，控制整个实例的内存上限，这种方案需要在数据库层（例如MySQL）也存储一份映射关系，当Redis中的缓存过期或被淘汰时，需要从数据库中重新查询重建缓存，同时需要保证数据库和缓存的一致性，这些逻辑也需要编写业务代码实现。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;省内存&quot;&gt;&lt;a href=&quot;#省内存&quot; class=&quot;headerlink&quot; title=&quot;省内存&quot;&gt;&lt;/a&gt;省内存&lt;/h1&gt;&lt;h2 id=&quot;为什么-String-类型内存开销大？&quot;&gt;&lt;a href=&quot;#为什么-String-类型内存开销大？&quot; class=&quot;he</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-原则</title>
    <link href="http://example.com/2020/09/14/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%88%99/"/>
    <id>http://example.com/2020/09/14/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%88%99/</id>
    <published>2020-09-14T06:00:17.000Z</published>
    <updated>2021-09-19T15:58:00.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="单一职责（SRP）"><a href="#单一职责（SRP）" class="headerlink" title="单一职责（SRP）"></a>单一职责（SRP）</h2><p><strong>一个类或者模块只负责完成一个职责</strong>，不要设计大而全的类，要设计粒度小、功能单一的类。换个角度来讲就是，一个类包含了两个或者两个以上业务不相干的功能，那我们就说它职责不够单一，应该将它拆分成多个功能更加单一、粒度更细的类。</p><h3 id="如何判断类的职责是否足够单一？"><a href="#如何判断类的职责是否足够单一？" class="headerlink" title="如何判断类的职责是否足够单一？"></a>如何判断类的职责是否足够单一？</h3><p>不同的应用场景、不同阶段的需求背景下，对同一个类的职责是否单一的判定，可能都是不一样的<br>比如业务简单就是要展示用户信息，所以省市区等字段都写到userinfo都没事<br>但是后面业务扩展多了电商物流等业务，可能就要把地址拆分成单独的，需求变了，单一的定义也就变了<br>虽然一开始就拆容易拓展但也有问题：一条数据库信息要创建多个类，如果数据库也拆了就要做多次数据库操作</p><p><strong>可以先写一个粗粒度的类，满足业务需求。随着业务的发展，如果粗粒度的类越来越庞大，代码越来越多，这个时候，我们就可以将这个粗粒度的类，拆分成几个更细粒度的类</strong>。这就是所谓的持续重构</p><p>判断单一的几条参考原则：</p><ol><li>类中的代码行数、函数或属性过多，会影响代码的可读性和可维护性，我们就需要考虑对类进行拆分</li><li>类依赖的其他类过多，或者依赖类的其他类过多，不符合高内聚、低耦合的设计思想，我们就需要考虑对类进行拆分</li><li>私有方法过多，我们就要考虑能否将私有方法独立到新的类中，设置为 public 方法，供更多的类使用，从而提高代码的复用性</li><li>比较难给类起一个合适名字，很难用一个业务名词概括，或者只能用一些笼统的 Manager、Context 之类的词语来命名，这就说明类的职责定义得可能不够清晰</li><li>类中大量的方法都是集中操作类中的某几个属性，比如，在 UserInfo 例子中，如果一半的方法都是在操作 address 信息，那就可以考虑将这几个属性和对应的方法拆分出来。</li></ol><h3 id="类的职责是否设计得越单一越好？"><a href="#类的职责是否设计得越单一越好？" class="headerlink" title="类的职责是否设计得越单一越好？"></a>类的职责是否设计得越单一越好？</h3><p>单一职责原则通过避免设计大而全的类，避免将不相关的功能耦合在一起，来提高类的内聚性。同时，类职责单一，类依赖的和被依赖的其他类也会变少，减少了代码的耦合性，以此来实现代码的高内聚、低耦合。但是，如果拆分得过细，实际上会适得其反，反倒会降低内聚性，也会影响代码的可维护性。</p><h2 id="开闭原则-OCP"><a href="#开闭原则-OCP" class="headerlink" title="开闭原则(OCP)"></a>开闭原则(OCP)</h2><p>怎样的代码改动才被定义为‘扩展’？<br>怎样的代码改动才被定义为‘修改’？<br>怎么才算满足或违反‘开闭原则’？<br>修改代码就一定意味着违反‘开闭原则’吗？”</p><p>扩展性是代码质量最重要的衡量标准之一。在 23 种经典设计模式中，大部分设计模式都是为了解决代码的扩展性问题而存在的，主要遵从的设计原则就是开闭原则！</p><h3 id="怎么理解开闭原则？"><a href="#怎么理解开闭原则？" class="headerlink" title="怎么理解开闭原则？"></a>怎么理解开闭原则？</h3><p>我写的你别改，要加功能自己整—添加一个新的功能应该是，在已有代码基础上扩展代码（新增模块、类、方法等），而非修改已有代码</p><h3 id="如何做到“对扩展开放、修改关闭”？"><a href="#如何做到“对扩展开放、修改关闭”？" class="headerlink" title="如何做到“对扩展开放、修改关闭”？"></a>如何做到“对扩展开放、修改关闭”？</h3><p>具备扩展意识、抽象意识、封装意识。在写代码的时候，我们要多花点时间思考一下，这段代码未来可能有哪些需求变更，如何设计代码结构，事先留好扩展点，以便在未来需求变更的时候，在不改动代码整体结构、做到最小代码改动的情况下，将新的代码灵活地插入到扩展点上。<br>很多设计原则、设计思想、设计模式，都是以提高代码的扩展性为最终目的的。特别是 23 种经典设计模式，大部分都是为了解决代码的扩展性问题而总结出来的，都是以开闭原则为指导原则的。<br>最常用来提高代码扩展性的方法有：<strong>多态、依赖注入、基于接口而非实现编程</strong>，以及大部分的设计模式（比如，装饰、策略、模板、职责链、状态）。</p><p>对拓展开放是为了应对变化(需求)，对修改关闭是为了保证已有代码的稳定性；最终结果是为了让系统更有弹性！不然新增功能可能老代码都要测试</p><p>现在公司代码反思：<br>入参出参全是map，和oop不沾边，虽然接口复制粘贴改动小，但是数据不明确,一行一行看实现才能看出具体代码，校验逻辑及其数据转换贼墨迹，尤其强转</p><h2 id="里式替换（LSP）"><a href="#里式替换（LSP）" class="headerlink" title="里式替换（LSP）"></a>里式替换（LSP）</h2><h3 id="如何理解“里式替换原则”？"><a href="#如何理解“里式替换原则”？" class="headerlink" title="如何理解“里式替换原则”？"></a>如何理解“里式替换原则”？</h3><p>子类对象能够替换父类对象出现的任何地方，并保证原有逻辑正确。</p><h3 id="哪些代码明显违背了-LSP？"><a href="#哪些代码明显违背了-LSP？" class="headerlink" title="哪些代码明显违背了 LSP？"></a>哪些代码明显违背了 LSP？</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;单一职责（SRP）&quot;&gt;&lt;a href=&quot;#单一职责（SRP）&quot; class=&quot;headerlink&quot; title=&quot;单一职责（SRP）&quot;&gt;&lt;/a&gt;单一职责（SRP）&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;一个类或者模块只负责完成一个职责&lt;/strong&gt;，不要设计大而全的</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="设计模式" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis6-哨兵</title>
    <link href="http://example.com/2020/09/14/redis6-%E5%93%A8%E5%85%B5/"/>
    <id>http://example.com/2020/09/14/redis6-%E5%93%A8%E5%85%B5/</id>
    <published>2020-09-14T05:22:01.000Z</published>
    <updated>2021-09-14T07:57:53.292Z</updated>
    
    <content type="html"><![CDATA[<h1 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h1><p>运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p><p>监控主库运行状态，并判断主库是否客观下线；在主库客观下线后，选取新主库；选出新主库后，通知从库和客户端。</p><p><img src="/2020/09/14/redis6-%E5%93%A8%E5%85%B5/12.jpg" alt="导入"></p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>主管下线，客观下线<br>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。<br>从库下了无所谓，主的不行</p><p>客观下线：<br>通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断<br>当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”<br>也可以设置多少哨兵同意数量</p><h2 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h2><ol><li>除了要检查从库的当前在线状态，</li><li>还要判断它之前的网络连接状态<br>总是和主库断连，而且断连次数超出了一定的阈值 pass</li></ol><p><code>down-after-milliseconds * 10</code>。其中，<code>down-after-milliseconds</code> 是我们认定主从库断连的最大连接超时时间。如果在 <code>down-after-milliseconds</code> 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好<br>3. 优先级最高的从库得分高<br>通过 slave-priority 配置项，给不同的从库设置不同优先级(给配置好的设置优先级)<br>4. 和旧主库同步程度最接近的从库得分高。<br>主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。<br>slave_repl_offset 需要最接近 master_repl_offset<br>5. ID 号小的从库得分高</p><h2 id="哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？"><a href="#哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？" class="headerlink" title="哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？"></a>哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</h2><p>如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p><p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p><h2 id="配置哨兵"><a href="#配置哨兵" class="headerlink" title="配置哨兵"></a>配置哨兵</h2><p>配置哨兵的信息时，我们只需要用到下面的这个配置项，<br><code>sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;</code><br>设置主库的 IP 和端口，并没有配置其他哨兵的连接信息。sentinel monitor<br>哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢?</p><p><strong>基于 pub/sub 机制的哨兵集群组成</strong><br><strong>哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。</strong><br>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。<br>Redis 会以频道的形式，对这些消息进行分门别类的管理<br>只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换</p><p><strong>哨兵是如何知道从库的 IP 地址和端口的呢？</strong><br>哨兵向主库发送 INFO 命令<br>主库接受到这个命令后，就会把从库列表返回给哨兵</p><p><strong>基于 pub/sub 机制的客户端事件通知</strong><br><strong>由哪个哨兵执行主从切换？</strong><br>“Leader 选举”<br>满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值</p><p>：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。</p><p><strong>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？</strong></p><p>经过实际测试，我的结论如下：</p><p>1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。</p><p>2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;哨兵&quot;&gt;&lt;a href=&quot;#哨兵&quot; class=&quot;headerlink&quot; title=&quot;哨兵&quot;&gt;&lt;/a&gt;哨兵&lt;/h1&gt;&lt;p&gt;运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis5-主从</title>
    <link href="http://example.com/2020/09/12/redis5-%E4%B8%BB%E4%BB%8E/"/>
    <id>http://example.com/2020/09/12/redis5-%E4%B8%BB%E4%BB%8E/</id>
    <published>2020-09-12T06:00:17.000Z</published>
    <updated>2021-09-14T07:57:02.039Z</updated>
    
    <content type="html"><![CDATA[<h1 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h1><p>redis为什么可靠？一是数据尽量少丢失，二是服务尽量少中断。<br>AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上</p><p>Redis 提供了主从库模式，以保证数据副本的一致，<br>主从库之间采用的是<strong>读写分离的方式</strong>。</p><p>读操作：主库、从库都可以接收；<br>写操作：首先到主库执行，然后，主库将写操作同步给从库。</p><p><img src="/2020/09/12/redis5-%E4%B8%BB%E4%BB%8E/10.jpg" alt="导入"></p><p>为什么读写分离？<br>不分离，同一数据，一个实例写一次，怎么保证一致？加锁？开销大</p><h2 id="第一次同步"><a href="#第一次同步" class="headerlink" title="第一次同步"></a>第一次同步</h2><p>实例1执行replicaof<br><code>replicaof 172.16.19.3 6379</code><br>就会成为实例2（172.16.19.3） 的从库，主从<br><img src="/2020/09/12/redis5-%E4%B8%BB%E4%BB%8E/11.jpg" alt="导入"></p><ol><li>建立连接、协商同步的过程</li></ol><p>主要是为全量复制做准备。在这一步，<strong>从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。</strong><br>从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。<strong>psync 命令包含了主库的 runID 和复制进度 offset</strong>。<br>runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。<br>offset，此时设为 -1，表示第一次复制。<br>主库收到 psync 命令后，会用 <code>FULLRESYNC</code> 响应命令带上两个参数：主库 <code>runID</code> 和主库目前的复制进度 <code>offset</code>，返回给从库。从库收到响应后，会记录下这两个参数。<br><code>FULLRESYNC</code> <strong>响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库</strong>。</p><ol start="2"><li>RDB同步</li></ol><p>在第二阶段，<strong>主库将所有数据同步给从库。从库收到数据后会先清空当前数据库！！！！，然后在本地完成数据加载</strong>。这个过程依赖于内存快照生成的 RDB 文件。</p><ol start="3"><li>追加新的写命令</li></ol><p>在主库将数据<strong>同步给从库的过程中，主库不会被阻塞</strong>，仍然可以正常接收请求。<br>期间的写操作会记录到内存中专用的<code>replication buffer</code>中<br>主库完成 RDB 文件发送后，就会把此时 <code>replication buffer</code> 中的修改操作发给从库</p><p>同步完成</p><p>注： psync 这个动作 执行 RDB 全量数据，是直接传输到从库上，还是先落到主redis 磁盘上？<br>Redis在全量复制时，既支持先生成RDB文件，再把RDB文件传给从库，也支持在主库上直接通过socket把数据传给从库，这称为无盘复制。<br>如果运行主库的机器磁盘性能不太好，但是网络性能不错的话，可以考虑无盘复制。</p><h2 id="主从级联模式"><a href="#主从级联模式" class="headerlink" title="主从级联模式"></a>主从级联模式</h2><p>从库多了，主库不用干别的，一直忙着fork和传rdb文件了<br>可以主-从=从</p><h2 id="主从断网"><a href="#主从断网" class="headerlink" title="主从断网"></a>主从断网</h2><p>为了避免连接开销<br>主从都是长链接的<br>万一断网，从库不更新，读到从库旧数据怎么办？<br>2.8之前，只要断了从新连上之后就会全量复制<br>2.8之后：增量，把主从库网络断连期间主库收到的命令，同步给从库。<br>当主从库断连后，主库会把断连期间收到的写操作命令，写入 <code>replication buffer</code>，同时也会把这些操作命令也写入<code>repl_backlog_buffer</code> 这个缓冲区。<br><code>repl_backlog_buffer</code> 是<strong>一个环形缓冲区</strong>，<font color="red/">主库会记录自己写到的位置，从库则会记录自己已经读到的位置。<br>主库偏移量 <code>master_repl_offset</code>，从库已复制的偏移量 <code>slave_repl_offset</code><br>主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。<br><strong>repl_backlog_buffer是所有从库共享的</strong>，slave_repl_offset是由从库自己记录的，这也是因为每个从库的复制进度不一定相同。</font></p><p>注意：<br><code>repl_backlog_buffer</code> 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，<br>此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。（可以调整 repl_backlog_size 这个参数）<br>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小<br>举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。</p><p>不过再大也可能完犊子，万一停机一天的从库连上来呢？</p><p>其实从库正常情况下会每秒给主库发送一个<code>replconf ack</code>命令，主库会根据这个命令的达到时间判断和从库的连网情况。如果距离最后一次ack命令收到的时间已经超过了repl_timeout时间，就会和从库断开连接了。</p><p>从库再和主库连接时，通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，如果要复制内容在缓冲区中已经被覆盖了，那么就不再做增量复制了，而是进行<strong>全量复制</strong>。</p><p>主从库同步的基本原理，总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。</p><h2 id="主从库间的复制不使用-AOF"><a href="#主从库间的复制不使用-AOF" class="headerlink" title="主从库间的复制不使用 AOF"></a>主从库间的复制不使用 AOF</h2><p>1、RDB文件内容是经过压缩的二进制数据，文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。<br>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p><h2 id="repl-backlog-buffer和replication-buffer理解"><a href="#repl-backlog-buffer和replication-buffer理解" class="headerlink" title="repl_backlog_buffer和replication buffer理解"></a>repl_backlog_buffer和replication buffer理解</h2><p>1、repl_backlog_buffer：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。如果从库断开时间太久，<code>repl_backlog_buffer</code>环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以<code>repl_backlog_buffer</code>配置尽量大一些，可以降低主从断开后全量同步的概率。而在<code>repl_backlog_buffer</code>中找主从差异的数据后，如何发给从库呢？这就用到了<code>replication buffer</code>。</p><p>2、replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做<code>replication buffer</code>。</p><p>既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了<code>client-output-buffer-limit</code>参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果<strong>从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;主从&quot;&gt;&lt;a href=&quot;#主从&quot; class=&quot;headerlink&quot; title=&quot;主从&quot;&gt;&lt;/a&gt;主从&lt;/h1&gt;&lt;p&gt;redis为什么可靠？一是数据尽量少丢失，二是服务尽量少中断。&lt;br&gt;AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>java一些基础巩固</title>
    <link href="http://example.com/2020/09/09/java%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/"/>
    <id>http://example.com/2020/09/09/java%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/</id>
    <published>2020-09-09T04:23:19.000Z</published>
    <updated>2021-09-14T08:33:30.542Z</updated>
    
    <content type="html"><![CDATA[<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 编译器自动优化成：不然会创建&quot;ab&quot;、&quot;cd&quot;、&quot;ef&quot;、&quot;abce&quot;、“abcdef”多个</span></span><br><span class="line">String str= <span class="string">&quot;ab&quot;</span> + <span class="string">&quot;cd&quot;</span> + <span class="string">&quot;ef&quot;</span>;</span><br><span class="line">String str= <span class="string">&quot;abcdef&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">1000</span>; i++) &#123;</span><br><span class="line">      str = str + i;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 编译器自动优化成</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">1000</span>; i++) &#123;</span><br><span class="line">       str = (<span class="keyword">new</span> StringBuilder(String.valueOf(str))).append(i).toString();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 为什么编译器提示循环里面的字符串最好用stringBuilder?即使不显示的创建，编译器也会在循环里面创建，但是里面会创建1000次stringBuilder，不如自己在外面定义一次</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// intern可以避免内存浪费，如果常量池存在&quot;abc&quot;，并不会创建b,而是将b创建的堆内存当垃圾回收,b指向的还是常量池中的“abc”和一样</span></span><br><span class="line">String a =<span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>).intern();</span><br><span class="line">String b = <span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>).intern();</span><br><span class="line">System.out.print(a==b); <span class="comment">//结果是true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.7之前string :char 数组、偏移量 offset、字符数量 count、哈希值 hash</span></span><br><span class="line"><span class="comment">// 1.7-1.8 :不再有 offset 和 count 两个变量了。这样的好处是 String 对象占用的内存稍微少了些，同时，String.substring 方法也不再共享 char[]，从而解决了使用该方法可能导致的内存泄漏问题。</span></span><br><span class="line"><span class="comment">// 1.9 : char[] 字段改为了 byte[] 字段，又维护了一个新的属性 coder,降低了内存（char 字符占 16 位，2 个字节。byte占 8 位，1 个字节  ）</span></span><br></pre></td></tr></table></figure><ul><li>不可变的好处：</li></ul><ol><li>安全性，防止恶意篡改</li><li>hash 属性值不会频繁变更，确保了唯一性，使得类似 HashMap 容器才能实现相应的 key-value 缓存功能。</li><li>实现字符串常量池：减少同一个值的字符串对象的重复创建，节约内存。</li></ol><ul><li>慎用Split+正则：回溯问题，避免回溯的方法就是：使用懒惰模式（正则加“?”）和独占模式(正则加”+”号)。</li></ul><h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><ol><li><p>对象数组 elementData 使用了 transient 修饰，却又实现了 Serializable 接口为什么？<br>如果采用外部序列化法实现数组的序列化，会序列化整个数组。ArrayList 为了避免这些没有存储数据的内存空间被序列化，内部提供了两个私有方法 writeObject 以及 readObject 来自我完成序列化与反序列化，从而在序列化与反序列化数组时节省了空间和时间。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">// 默认初始化容量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// 对象数组</span></span><br><span class="line"><span class="keyword">transient</span> Object[] elementData; </span><br><span class="line"><span class="comment">// 数组长度</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size;</span><br></pre></td></tr></table></figure><p>同理LinkedList :序列化的时候不会只对头尾进行序列化，所以 LinkedList 也是自行实现 readObject 和 writeObject 进行序列化与反序列化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">transient</span> Node&lt;E&gt; first;</span><br><span class="line"><span class="keyword">transient</span> Node&lt;E&gt; last;</span><br></pre></td></tr></table></figure></li><li><p>ArrayList添加操作慢？<br>在没有扩容的情况下，ArrayList 的效率要高于 LinkedList。这是因为 ArrayList 在添加元素到尾部的时候，不需要复制重排数据，效率非常高。而 LinkedList 虽然也不用循环查找元素，但 LinkedList 中多了 new 对象以及变换指针指向对象的过程，所以效率要低于 ArrayList。（删除同理）</p></li><li><p>遍历选择：<br>LinkedList 切忌使用 for ：太慢，每次都是从头找，使用迭代器</p></li><li><p>ArrayList删除注意：</p><p>错误写法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(ArrayList&lt;String&gt; list)</span> </span></span><br><span class="line"><span class="function"> </span>&#123;</span><br><span class="line">     <span class="keyword">for</span> (String s : list)</span><br><span class="line">     &#123;</span><br><span class="line">         <span class="keyword">if</span> (s.equals(<span class="string">&quot;b&quot;</span>)) </span><br><span class="line">         &#123;</span><br><span class="line">             list.remove(s);</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>正确：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(ArrayList&lt;String&gt; list)</span> </span></span><br><span class="line"><span class="function"> </span>&#123;</span><br><span class="line">     Iterator&lt;String&gt; it = list.iterator();</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">         String str = it.next();</span><br><span class="line">         </span><br><span class="line">         <span class="keyword">if</span> (str.equals(<span class="string">&quot;b&quot;</span>)) &#123;</span><br><span class="line">             it.remove();</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line"> </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>for(:)循环[这里指的不是for(;;)]是一个语法糖，这里会被解释为迭代器，在使用迭代器遍历时，<code>ArrayList</code>内部创建了一个内部迭代器<code>iterator</code>，在使用<code>next()</code>方法来取下一个元素时，会使用<code>ArrayList</code>里保存的一个用来记录<code>List</code>修改次数的变量<code>modCount</code>，与<code>iterator</code>保存了一个<code>expectedModCount</code>来表示期望的修改次数进行比较，如果不相等则会抛出异常；</p></li></ol><p>而在在<code>foreach</code>循环中调用<code>list</code>中的<code>remove()</code>方法，会走到<code>fastRemove()</code>方法，该方法不是<code>iterator</code>中的方法，而是<code>ArrayList</code>中的方法，在该方法只做了<code>modCount++</code>，而没有同步到<code>expectedModCount</code>。</p><p>当再次遍历时，会先调用内部类<code>iteator</code>中的<code>hasNext()</code>,再调用<code>next()</code>,在调用<code>next()</code>方法时，会对<code>modCount</code>和<code>expectedModCount</code>进行比较，此时两者不一致，就抛出了<code>ConcurrentModificationException</code>异常。</p><p>所以关键是用<code>ArrayList</code>的<code>remove</code>还是<code>iterator</code>中的<code>remove</code>。</p><p>ArrayList 是非线程安全容器，在并发场景下使用很可能会导致线程安全问题。这时，我们就可以考虑使用 Java 在并发编程中提供的线程安全数组，包括 Vector 和 CopyOnWriteArrayList。</p><p>Vector 也是基于 Synchronized 同步锁实现的线程安全，Synchronized 关键字几乎修饰了所有对外暴露的方法，所以在读远大于写的操作场景中，Vector 将会发生大量锁竞争，从而给系统带来性能开销。</p><p>相比之下，CopyOnWriteArrayList 是 java.util.concurrent 包提供的方法，它实现了读操作无锁，写操作则通过操作底层数组的新副本来实现，是一种读写分离的并发策略</p><h2 id="hashmap"><a href="#hashmap" class="headerlink" title="hashmap"></a>hashmap</h2><ol><li><p>设置初始容量，一般得是 2 的整数次幂?<br>就是减少哈希冲突，均匀分布元素。<br>通过将 Key 的 hash 值与 length-1 进行 &amp; 运算，实现了当前 Key 的定位，2 的幂次方可以减少冲突（碰撞）的次数，提高 HashMap 查询效率；<br>如果 length 为 2 的次幂，则 length-1 转化为二进制必定是 11111…… 的形式，在于 h 的二进制与操作效率会非常的快，而且空间不浪费<br>2的幂次方减1后每一位都是1，让数组每一个位置都能添加到元素。<br>例如十进制8，对应二进制1000，减1是0111，这样在&amp;hash值使数组每个位置都是可以添加到元素的，如果有一个位置为0，那么无论hash值是多少那一位总是0，例如0101，&amp;hash后第二位总是0，也就是说数组中下标为2的位置总是空的。</p></li><li><p>为什么JDK1.8之前，链表元素增加采用的是头插法，1.8之后改成尾插法了<br>JDK1.7是考虑新增数据大多数是热点数据，所以考虑放在链表头位置，也就是数组中，这样可以提高查询效率，但这种方式会出现插入数据是逆序的。在JDK1.8开始hashmap链表在节点长度达到8之后会变成红黑树，这样一来在数组后节点长度不断增加时，遍历一次的次数就会少很多，相比头插法而言，尾插法操作额外的遍历消耗已经小很多了。</p></li><li><p>为什么阈值是8？链表长度超过8一定会转红黑树吗？<br>根据时间复杂度，为8时链表和红黑树都是一样的，超过8红黑树复杂度更低<br>还有个要求，元素数量超过64（<code>MIN_TREEIFY_CAPACITY</code>）</p></li><li><p>为什么红黑树退化链表的阈值是6不是7？<br>防止来回在红黑树和链表之间转换，避免频繁转换的开销（树的左旋右旋）</p></li></ol><p>线程安全的：如果对数据有强一致要求，则需使用 Hashtable；在大部分场景通常都是弱一致性的情况下，使用 ConcurrentHashMap 即可；如果数据量在千万级别，且存在大量增删改操作，则可以考虑使用 ConcurrentSkipListMap。</p><p>ConcurrentHashMap有些方法是没有锁的，例如get 方法。假设A修改了数据，而B后于A一瞬间去获取数据，有可能拿到的数据是A修改之前的数据。</p><h2 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h2><ul><li><p>Java 发布了 NIO 的升级包 NIO2，也就是 AIO。AIO 实现了真正意义上的异步 I/O，它是直接将 I/O 操作交给操作系统进行异步处理。这也是对 I/O 操作的一种优化，那为什么现在很多容器的通信框架都还是使用 NIO 呢？</p><p> 异步I/O模型在Linux内核中没有实现</p></li></ul><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Singleton singleInstance = <span class="keyword">new</span> Singleton();</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">       <span class="keyword">return</span> singleInstance; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码问题：序列化会通过反射调用无参构造器返回一个新对象，破坏单例模式。<br>解决方法是添加readResolve()方法，自定义返回对象策略。</p><p>java序列化： 仅对对象的非 transient 的实例变量进行序列化，而不会序列化对象的 transient 的实例变量，也不会序列化静态变量。<br>在实现了 Serializable 接口的类的对象中，会生成一个 serialVersionUID 的版本号,它会在反序列化过程中来验证序列化对象是否加载了反序列化的类，如果是具有相同类名的不同版本号的类，在反序列化中是无法获取对象的。具体实现序列化的是 writeObject 和 readObject，通常这两个方法是默认的，当然我们也可以在实现 Serializable 接口的类中对其进行重写，定制一套属于自己的序列化与反序列化机制。另外，Java 序列化的类中还定义了两个重写方法：writeReplace() 和 readResolve()，前者是用来在序列化之前替换序列化对象的，后者是用来在反序列化之后对返回对象进行处理的。</p><ul><li>Java 序列化的缺陷<ol><li>无法跨语言: Java 序列化目前只适用基于 Java 语言实现的框架，其它语言大部分都没有使用 Java 的序列化框架，也没有实现 Java 序列化这套协议</li><li>易被攻击</li><li>性能差</li></ol></li><li>代替：<br>SpringCloud 用的是 Json 序列化<br>近两年比较火的 Protobuf 序列化<br>Dubbo+Protobuf 序列化</li></ul><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h3><p><img src="/2020/09/09/java%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/%E9%94%81.png" alt="1"></p><p>为了提升性能，JDK1.6 引入了偏向锁、轻量级锁、重量级锁概念，来减少锁竞争带来的上下文切换，而正是新增的 Java 对象头实现了锁升级功能。</p><p>当 Java 对象被 Synchronized 关键字修饰成为同步锁后，围绕这个锁的一系列升级操作都将和 Java 对象头有关。</p><p>锁升级功能主要依赖于 Mark Word 中的锁标志位和释放偏向锁标志位，Synchronized 同步锁就是从偏向锁开始的，随着竞争越来越激烈，偏向锁升级到轻量级锁，最终升级到重量级锁。</p><ol><li>偏向锁<br>偏向锁的作用就是，当一个线程再次访问这个同步代码或方法时，该线程只需去对象头的 Mark Word 中去判断一下是否有偏向锁指向它的 ID，无需再进入 Monitor 去竞争对象了。当对象被当做同步锁并有一个线程抢到了锁时，锁标志位还是 01，“是否偏向锁”标志位设置为 1，并且记录抢到锁的线程 ID，表示进入偏向锁状态。</li></ol><p>在高并发场景下，当大量线程同时竞争同一个锁资源时，偏向锁就会被撤销，发生 stop the word 后， 开启偏向锁无疑会带来更大的性能开销，这时我们可以通过添加 JVM 参数关闭偏向锁来调优系统性能<br><code>-XX:-UseBiasedLocking // 关闭偏向锁（默认打开）</code><br>2. 轻量级锁</p><p>当有另外一个线程竞争获取这个锁时，由于该锁已经是偏向锁，当发现对象头 Mark Word 中的线程 ID 不是自己的线程 ID，就会进行 CAS 操作获取锁，如果获取成功，直接替换 Mark Word 中的线程 ID 为自己的 ID，该锁会保持偏向锁状态；如果获取锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。<br>轻量级锁适用于线程交替执行同步块的场景，绝大部分的锁在整个同步周期内都不存在长时间的竞争。<br>3. 自旋锁与重量级锁</p><p>轻量级锁 CAS 抢锁失败，线程将会被挂起进入阻塞状态。如果正在持有锁的线程在很短的时间内释放资源，那么进入阻塞状态的线程无疑又要申请锁资源。</p><p>JVM 提供了一种自旋锁，可以通过自旋方式不断尝试获取锁，从而避免线程被挂起阻塞。这是基于大多数情况下，线程持有锁的时间都不会太长，毕竟线程被挂起阻塞可能会得不偿失。<br>自旋锁重试之后如果抢锁依然失败，同步锁就会升级至重量级锁，锁标志位改为 10。在这个状态下，未抢到锁的线程都会进入 Monitor，之后会被阻塞在 _WaitSet 队列中。<br>在锁竞争不激烈且锁占用时间非常短的场景下，自旋锁可以提高系统性能。！！！<br>一旦锁竞争激烈或锁占用的时间过长，自旋锁将会导致大量的线程一直处于 CAS 重试状态，占用 CPU 资源，反而会增加系统性能开销。所以自旋锁和重量级锁的使用都要结合实际场景。<br>在高负载、高并发的场景下，我们可以通过设置 JVM 参数来关闭自旋锁，优化系统性能，示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-XX:-UseSpinning <span class="comment">// 参数关闭自旋锁优化 (默认打开) </span></span><br><span class="line">-XX:PreBlockSpin <span class="comment">// 参数修改默认的自旋次数。JDK1.7 后，去掉此参数，由 jvm 控制</span></span><br></pre></td></tr></table></figure><ol start="4"><li>动态编译实现锁消除 / 锁粗化<br>JIT 编译器在动态编译同步块的时候，借助了一种被称为逃逸分析的技术，来判断同步块使用的锁对象是否只能够被一个线程访问，而没有被发布到其它线程。<br>确认是的话，那么 JIT 编译器在编译这个同步块的时候不会生成 synchronized 所表示的锁的申请与释放的机器码，即消除了锁的使用</li></ol><p>锁粗化同理，就是在 JIT 编译器动态编译时，如果发现几个相邻的同步块使用的是同一个锁实例，那么 JIT 编译器将会把这几个同步块合并为一个大的同步块，从而避免一个线程“反复申请、释放同一个锁“所带来的性能开销。<br>5. 减小锁粒度：锁分离、锁分段<br>读写锁实现了锁分离，也就是说读写锁是由“读锁”和“写锁”两个锁实现的，其规则是可以共享读，但只有一个写。<br>当我们的锁对象是一个数组或队列时，集中竞争一个对象的话会非常激烈，锁也会升级为重量级锁。我们可以考虑将一个数组和队列对象拆成多个小对象，来降低锁竞争，提升并行度。<br>ConcurrentHashMap 就很很巧妙地使用了分段锁 Segment 来降低锁资源竞争</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修饰普通方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// code</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 修饰静态方法:类锁！！！！！</span></span><br><span class="line"><span class="function"><span class="keyword">public</span>  <span class="keyword">synchronized</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">method2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JDK1.8，ConcurrentHashMap 做了大量的改动，摒弃了 Segment 的概念。由于 Synchronized 锁在 Java6 之后的性能已经得到了很大的提升，所以在 JDK1.8 中，Java 重新启用了 Synchronized 同步锁，通过 Synchronized 实现 HashEntry 作为锁粒度。这种改动将数据结构变得更加简单了，操作也更加清晰流畅。</p><h3 id="LOCK"><a href="#LOCK" class="headerlink" title="LOCK"></a>LOCK</h3><p> JVM 隐式获取和释放锁的 Synchronized 同步锁，Lock 同步锁（以下简称 Lock 锁）需要的是显示获取和释放锁<br> 这就为获取和释放锁提供了更多的灵活性。Lock 锁的基本操作是通过乐观锁来实现的，但由于 Lock 锁也会在阻塞时被挂起，因此它依然属于悲观锁。</p><p> <img src="/2020/09/09/java%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/%E9%94%81%E5%AF%B9%E6%AF%94.png" alt="1"></p><p> 并发量不高、竞争不激烈的情况下，Synchronized 同步锁由于具有分级锁的优势，性能上与 Lock 锁差不多<br> 高负载、高并发的情况下，Synchronized 同步锁由于竞争激烈会升级到重量级锁，性能则没有 Lock 锁稳定。</p><p>常用的实现类有 ReentrantLock、ReentrantReadWriteLock（RRW），它们都是依赖 AbstractQueuedSynchronizer（AQS）类实现的。</p><p>AQS 类结构中包含一个基于链表实现的等待队列（CLH 队列），用于存储所有阻塞的线程，AQS 中还有一个 state 变量，该变量对 ReentrantLock 来说表示加锁状态。</p><p>该队列的操作均通过 CAS 操作实现</p><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>线程创建多了导致上下文切换频繁。cpu、内存负载提高</p><p>一个线程被剥夺处理器的使用权而被暂停运行，就是“切出”；一个线程被选中占用处理器开始或者继续运行，就是“切入”。在这种切出切入的过程中，操作系统需要保存和恢复相应的进度信息，这个进度信息就是“上下文”了。</p><p>包括了寄存器的存储内容以及程序计数器存储的指令内容。CPU 寄存器负责存储已经、正在和将要执行的任务，程序计数器负责存储 CPU 正在执行的指令位置以及即将执行的下一条指令的位置。</p><p>当前 CPU 数量远远不止一个的情况下，操作系统将 CPU 轮流分配给线程任务，此时的上下文切换就变得更加频繁了，并且存在跨 CPU 上下文切换，比起单核上下文切换，跨核切换更加昂贵。</p><p>线程主要有“新建”（NEW）、“就绪”（RUNNABLE）、“运行”（RUNNING）、“阻塞”（BLOCKED）、“死亡”（DEAD）五种状态。</p><p>一种是程序本身触发的切换，这种我们称为自发性上下文切换，另一种是由系统或者虚拟机诱发的非自发性上下文切换。</p><p>自发性上下文切换指线程由 Java 程序调用导致切出，在多线程编程中，执行调用以下方法或关键字，常常就会引发自发性上下文切换。</p><p>sleep()<br>wait()<br>yield()<br>join()<br>park()<br>synchronized<br>lock<br>非自发性上下文切换指线程由于调度器的原因被迫切出。常见的有：线程被分配的时间片用完，虚拟机垃圾回收导致或者执行优先级的问题导致。</p><p>使用 Linux 内核提供的 vmstat 命令，来监视 Java 程序运行过程中系统的上下文切换频率</p><p>监视某个应用的上下文切换，就可以使用 pidstat 命令监控指定进程的 Context Switch 上下文切换。</p><p>多线程中使用 Synchronized 还会发生进程间的上下文切换吗？</p><p>进程上下文切换，是指用户态和内核态的来回切换。我们知道，如果一旦Synchronized锁资源竞争激烈，线程将会被阻塞，阻塞的线程将会从用户态调用内核态，尝试获取mutex，这个过程就是进程上下文切换。</p><p>上下文切换是多线程编程性能消耗的原因之一，而竞争锁、线程间的通信以及过多地创建线程等多线程编程操作，都会给系统带来上下文切换。除此之外，I/O 阻塞以及 JVM 的垃圾回收也会增加上下文切换。</p><p>总的来说，过于频繁的上下文切换会影响系统的性能，所以我们应该避免它。另外，我们还可以将上下文切换也作为系统的性能参考指标，并将该指标纳入到服务性能监控，防患于未然。</p><p>ThreadPoolExecutor 创建线程池：</p><p>默认情况下，线程池中并没有任何线程，等到有任务来才创建线程去执行任务。</p><p>但有一种情况排除在外，就是调用 prestartAllCoreThreads() 或者 prestartCoreThread() 方法的话，可以提前创建等于核心线程数的线程数量，这种方式被称为预热，在抢购系统中就经常被用到。</p><p>当创建的线程数等于 corePoolSize 时，提交的任务会被加入到设置的阻塞队列中。当队列满了，会创建线程执行任务，直到线程池中的数量等于 maximumPoolSize。</p><p>当线程数量已经等于 maximumPoolSize 时， 新提交的任务无法加入到等待队列，也无法创建非核心线程直接执行，我们又没有为线程池设置拒绝策略，这时线程池就会抛出 RejectedExecutionException 异常，即线程池拒绝接受这个任务。</p><p>当线程池中创建的线程数量超过设置的 corePoolSize，在某些线程处理完任务后，如果等待 keepAliveTime 时间后仍然没有新的任务分配给它，那么这个线程将会被回收。线程池回收线程时，会对所谓的“核心线程”和“非核心线程”一视同仁，直到线程池中线程的数量等于设置的 corePoolSize 参数，回收过程才会停止。</p><p> <img src="/2020/09/09/java%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A9%E5%9B%BA/%E7%BA%BF%E7%A8%8B%E6%B1%A0.png" alt="1"></p><p> 一般多线程执行的任务类型可以分为 CPU 密集型和 I/O 密集型，根据不同的任务类型，我们计算线程数的方法也不一样。</p><p> 线程数 =N（CPU 核数）*（1+WT（线程等待时间）/ST（线程时间运行时间））</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;String&quot;&gt;&lt;a href=&quot;#String&quot; class=&quot;headerlink&quot; title=&quot;String&quot;&gt;&lt;/a&gt;String&lt;/h2&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutt</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>redis4-RDB</title>
    <link href="http://example.com/2020/09/09/redis4-RDB/"/>
    <id>http://example.com/2020/09/09/redis4-RDB/</id>
    <published>2020-09-09T04:23:19.000Z</published>
    <updated>2021-09-14T07:52:24.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RDB快照"><a href="#RDB快照" class="headerlink" title="RDB快照"></a>RDB快照</h1><p>AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响到正常使用</p><p>RDB内存快照：记录的是某一时刻的数据（<strong>全量数据</strong>）</p><p>save：在主线程中执行，会导致阻塞<br>bgsave：创建一个子进程，专门用于写入 RDB 文件（默认）</p><h2 id="创建RDB期间，redis还能提供写操作"><a href="#创建RDB期间，redis还能提供写操作" class="headerlink" title="创建RDB期间，redis还能提供写操作"></a>创建RDB期间，redis还能提供写操作</h2><p>Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。<br>bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。<br>主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份副本，主线程在副本上进行修改。同时，bgsave 子进程可以继续把原来的数据写入 RDB 文件。</p><p><img src="/2020/09/09/redis4-RDB/9.jpg" alt="导入"></p><h2 id="多久一次"><a href="#多久一次" class="headerlink" title="多久一次"></a>多久一次</h2><p>不能太频繁，多个快照写入竞争磁盘带宽，且fork过程会阻塞主线程<br>同时<br>Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程（霸道）</p><h2 id="RDB风险"><a href="#RDB风险" class="headerlink" title="RDB风险"></a>RDB风险</h2><p>例如：2核CPU、4GB内存、500G磁盘，Redis实例占用2GB，写读比例为8:2，此时做RDB持久化，产生的风险主要在于 CPU资源 和 内存资源 这2方面：</p><p>a、内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。</p><p>b、CPU资源风险：虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</p><h2 id="增量快照"><a href="#增量快照" class="headerlink" title="增量快照"></a>增量快照</h2><p>全量之后只对修改过的数据进行记录<br>怎么记录—-AOF reids4.0 实现两种持久化的结合：一定频率执行RDB，两次RDB期间AOF</p><p>不用频繁forK rdb &amp;&amp;重写 进程，不用频繁重写AOF文件</p><h2 id="关于-AOF-和-RDB-的选择问题"><a href="#关于-AOF-和-RDB-的选择问题" class="headerlink" title="关于 AOF 和 RDB 的选择问题"></a>关于 AOF 和 RDB 的选择问题</h2><p>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；<br>如果允许分钟级别的数据丢失，可以只使用 RDB；<br>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;RDB快照&quot;&gt;&lt;a href=&quot;#RDB快照&quot; class=&quot;headerlink&quot; title=&quot;RDB快照&quot;&gt;&lt;/a&gt;RDB快照&lt;/h1&gt;&lt;p&gt;AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis3-AOF</title>
    <link href="http://example.com/2020/09/05/redis3-AOF/"/>
    <id>http://example.com/2020/09/05/redis3-AOF/</id>
    <published>2020-09-05T05:05:21.000Z</published>
    <updated>2021-09-14T07:52:34.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AOF日志"><a href="#AOF日志" class="headerlink" title="AOF日志"></a>AOF日志</h1><p>不同于数据库的写前日志<br>AOF是写后日志： Redis 是先执行命令，把数据写入内存，然后才记录日志<br>记录的是 Redis 收到的每一条命令</p><h2 id="为什么先执行后记录AOF"><a href="#为什么先执行后记录AOF" class="headerlink" title="为什么先执行后记录AOF"></a>为什么先执行后记录AOF</h2><ol><li><p>为了避免额外的检查开销<br>Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。<br>所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。<br>先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。</p></li><li><p>不会阻塞当前的操作<br>先解决redis要干的正事，正事干完了再持久化，redis为了快<br>但是先执行完再写，还是先写再执行，意义不大？AOF也是在主线程执行的</p></li></ol><h2 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h2><ol><li><p>刚执行完一个命令，还没有来得及记日志就宕机了<br>如果redis是缓存，重新读。但如果是做数据库，数据就丢了</p></li><li><p>如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p></li></ol><p>控制一个写命令执行完后 AOF 日志写回磁盘的时机上述风险可以降低</p><h2 id="写回策略"><a href="#写回策略" class="headerlink" title="写回策略"></a>写回策略</h2><p>Always：同步写会，执行完立马写</p><p>Everysec：每秒写回，执行完，先写到缓冲区，一秒后缓冲区写到磁盘（建议）</p><p>No：系统写回，写到缓冲区，系统决定何时写入磁盘</p><p>可靠性逐渐减低，性能逐渐提高，看业务自行取舍</p><h2 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h2><p>不断追加aof文件过大，往大文件里写数据效率会减低，影响主线程，影响redis性能</p><p>重写机制具有“多变一”：一条命令反复修改时，aof记录最终的结果</p><p>每次 AOF 重写时，主进程fork子进程，子进程拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。因为 Redis 采用额外的线程进行数据重写，所以不会阻塞主线程（但是fork过程会阻塞）</p><font color="red">aof重写是子进程bgrewriteaof 进行aof写回是主线程</font><h2 id="什么时候触发AOF重写"><a href="#什么时候触发AOF重写" class="headerlink" title="什么时候触发AOF重写"></a>什么时候触发AOF重写</h2><p>两个配置项在控制AOF重写的触发时机：</p><ol><li><p>auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB</p></li><li><p>auto-aof-rewrite-percentage: 这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。</p></li></ol><p>AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。</p><h2 id="AOF重写风险"><a href="#AOF重写风险" class="headerlink" title="AOF重写风险"></a>AOF重写风险</h2><ol><li>主进程fork子进程<br>fork这个瞬间一定是会阻塞主线程的<br>fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。</li></ol><p>fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。</p><h2 id="AOF-重写也有一个重写日志，为什么它不共享使用-AOF-本身的日志呢？"><a href="#AOF-重写也有一个重写日志，为什么它不共享使用-AOF-本身的日志呢？" class="headerlink" title="AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？"></a>AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？</h2><p>一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。<br>二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。</p><p>使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。—RDB牛逼了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AOF日志&quot;&gt;&lt;a href=&quot;#AOF日志&quot; class=&quot;headerlink&quot; title=&quot;AOF日志&quot;&gt;&lt;/a&gt;AOF日志&lt;/h1&gt;&lt;p&gt;不同于数据库的写前日志&lt;br&gt;AOF是写后日志： Redis 是先执行命令，把数据写入内存，然后才记录日志&lt;br&gt;记</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis2-单线</title>
    <link href="http://example.com/2020/09/02/redis2-%E5%8D%95%E7%BA%BF/"/>
    <id>http://example.com/2020/09/02/redis2-%E5%8D%95%E7%BA%BF/</id>
    <published>2020-09-02T04:51:13.000Z</published>
    <updated>2021-09-14T07:49:14.591Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么单线程"><a href="#为什么单线程" class="headerlink" title="为什么单线程"></a>为什么单线程</h1><p>1.多线程上下文切换<br>2.共享资源的并发访问控制：锁-&gt;等待-&gt;并行变串行</p><p>严格说：Redis 的网络 IO 和键值对读写是单线程，<br>持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><h2 id="为什么快"><a href="#为什么快" class="headerlink" title="为什么快"></a>为什么快</h2><p>1.大部分基于内存<br>2.多种数据结构：跳表，压缩，双向，哈希，数组等<br>3.多路复用机制</p><h2 id="linux的多路复用"><a href="#linux的多路复用" class="headerlink" title="linux的多路复用"></a>linux的多路复用</h2><p>一个线程处理多个 IO 流(select/epoll 机制)。<br>在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。<br>内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><h2 id="Redis单线程处理IO请求性能瓶颈主要包括2个方面"><a href="#Redis单线程处理IO请求性能瓶颈主要包括2个方面" class="headerlink" title="Redis单线程处理IO请求性能瓶颈主要包括2个方面"></a>Redis单线程处理IO请求性能瓶颈主要包括2个方面</h2><p>1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：</p><ul><li>操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；</li><li>使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</li><li>大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</li><li>淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</li><li>AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</li><li>主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</li><li>rehash扩容</li></ul><p>2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</p><p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p><p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;为什么单线程&quot;&gt;&lt;a href=&quot;#为什么单线程&quot; class=&quot;headerlink&quot; title=&quot;为什么单线程&quot;&gt;&lt;/a&gt;为什么单线程&lt;/h1&gt;&lt;p&gt;1.多线程上下文切换&lt;br&gt;2.共享资源的并发访问控制：锁-&amp;gt;等待-&amp;gt;并行变串行&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis1-数结</title>
    <link href="http://example.com/2020/09/01/redis1-%E6%95%B0%E7%BB%93/"/>
    <id>http://example.com/2020/09/01/redis1-%E6%95%B0%E7%BB%93/</id>
    <published>2020-09-01T11:55:23.000Z</published>
    <updated>2021-09-14T08:08:20.571Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数结"><a href="#数结" class="headerlink" title="数结"></a>数结</h1><p>使用了一个哈希表来保存所有键值对<br>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。</p><p>哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。<br><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/2.jpg" alt="1"></p><h2 id="为什么哈希表操作变慢了？"><a href="#为什么哈希表操作变慢了？" class="headerlink" title="为什么哈希表操作变慢了？"></a>为什么哈希表操作变慢了？</h2><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。毕竟，哈希桶的个数通常要少于 key 的数量，这也就是说，难免会有一些 key 的哈希值对应到了同一个哈希桶中。<br>Redis 解决哈希冲突的方式，就是链式哈希。<strong>链式哈希也很容易理解，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接</strong>。</p><p>rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突</p><p>使用了两个全局哈希表：类似JDK复制算法<br>哈希表 1 和哈希表 2<br>一开始使用哈希表 1，哈希表 2 没有分配空间。<br>rehash分为三步：<br>    给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；<br>    把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；<br>    释放哈希表 1 的空间。<br>    哈希表 1 留作下一次 rehash 扩容备用<br>问题：大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求</p><p>解决方法：渐进式 rehash<br>第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。</p><p><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/3.jpg" alt="导入"></p><p>对于 String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。</p><h2 id="集合数据操作效率"><a href="#集合数据操作效率" class="headerlink" title="集合数据操作效率"></a>集合数据操作效率</h2><p>第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查</p><p>集合的操作效率和哪些因素相关呢？<br>首先，与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点有关，比如读写一个元素的操作要比读写所有元素的效率高</p><p>集合类型的底层数据结构主要有 5 种：<strong>整数数组、双向链表、哈希表、压缩列表和跳表</strong>。<br><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/1.jpg" alt="导入"><br>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。<br>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。<br><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/4.jpg" alt="导入"></p><p><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/5.jpg" alt="导入"></p><p>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。</p><p>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。<strong>这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免</strong>。</p><p>从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p><p>统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p><p>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</p><p>Redis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set 也采用了 O(logN) 复杂度的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是 O(N)。这里，我的建议是：用其他命令来替代，例如可以用 SCAN 来代替，避免在 Redis 内部产生费时的全集合遍历操作。当然，我们不能忘了复杂度较高的 List 类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。因此，我的建议是：因地制宜地使用 List 类型。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合。</p><p>整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？</p><p>1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。</p><p>2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</p><h2 id="为什么-String-类型内存开销大"><a href="#为什么-String-类型内存开销大" class="headerlink" title="为什么 String 类型内存开销大"></a>为什么 String 类型内存开销大</h2><p>记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。</p><p>当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。</p><p>当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：</p><p><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/6.jpg" alt="导入"></p><p>buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。<br>len：占 4 个字节，表示 buf 的已用长度。<br>alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。<br>除了 SDS 的额外开销(len,alloc)，还有一个来自于 RedisObject 结构体的开销。<br>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址</p><p><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/7.jpg" alt="导入"></p><p>Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。<br>一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。<br>一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。<br>字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</p><p><img src="/2020/09/01/redis1-%E6%95%B0%E7%BB%93/8.jpg" alt="导入"></p><p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？我在第 2 讲中说过，Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：</p><p>但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。好了，到这儿，你应该就能理解，为什么用 String 类型保存图片 ID 和图片存储对象 ID 时需要用 64 个字节了。</p><h1 id="用什么数据结构可以节省内存？"><a href="#用什么数据结构可以节省内存？" class="headerlink" title="用什么数据结构可以节省内存？"></a>用什么数据结构可以节省内存？</h1><p>压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。<br>prev_len，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。<br>len：表示自身长度，4 字节；<br>encoding：表示编码方式，1 字节；<br>content：保存实际数据。</p><p>这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。</p><p>每个 entry 保存一个图片存储对象 ID（8 字节），此时，每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8=14），实际分配 16 字节。Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，一个图片 ID 只对应一个图片的存储对象 ID，我们该怎么用集合类型呢？换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？</p><h1 id="如何用集合类型保存单值的键值对？"><a href="#如何用集合类型保存单值的键值对？" class="headerlink" title="如何用集合类型保存单值的键值对？"></a>如何用集合类型保存单值的键值对？</h1><p>在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。<br>Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。这两个阈值分别对应以下两个配置项：hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。<br>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。<br>在内存空间的开销上，也许哈希表没有压缩列表高效<br>但是哈希表的查询效率，要比压缩列表高。<br>在对查询效率高的场景中，可以考虑空间换时间</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数结&quot;&gt;&lt;a href=&quot;#数结&quot; class=&quot;headerlink&quot; title=&quot;数结&quot;&gt;&lt;/a&gt;数结&lt;/h1&gt;&lt;p&gt;使用了一个哈希表来保存所有键值对&lt;br&gt;一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>分布式全局唯一ID</title>
    <link href="http://example.com/2020/08/19/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80ID/"/>
    <id>http://example.com/2020/08/19/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80ID/</id>
    <published>2020-08-19T04:12:10.000Z</published>
    <updated>2021-03-03T17:13:34.207Z</updated>
    
    <content type="html"><![CDATA[<p>在分布式系统中，经常需要使用全局唯一ID查找对应的数据。产生这种ID需要保证系统全局唯一，而且要高性能以及占用相对较少的空间。<br>全局唯一ID在数据库中一般会被设成主键，这样为了保证数据插入时索引的快速建立，还需要保持一个有序的趋势。<br>这样全局唯一ID就需要保证这两个需求：</p><ul><li>全局唯一</li><li>趋势有序<h1 id="全局ID产生的几种方式"><a href="#全局ID产生的几种方式" class="headerlink" title="全局ID产生的几种方式"></a>全局ID产生的几种方式</h1></li></ul><ol><li>数据库自增<br>当服务使用的数据库只有单库单表时，可以利用数据库的auto_increment来生成全局唯一递增ID.</li></ol><p><strong>优势</strong>：<br>简单，无需程序任何附加操作<br>保持定长的增量<br>在单表中能保持唯一性<br><strong>劣势</strong>：<br>高并发下性能不佳，主键产生的性能上限是数据库服务器单机的上限。<br>水平扩展困难，在分布式数据库环境下，无法保证唯一性。</p><ol start="2"><li>UUID<br>一般的语言中会自带<code>UUID</code>的实现，比如Java中UUID方式<code>UUID.randomUUID().toString()</code>，可以通过服务程序本地产生，ID的生成不依赖数据库的实现。</li></ol><p><strong>优势</strong>：<br>本地生成ID，不需要进行远程调用。<br>全局唯一不重复。<br>水平扩展能力非常好。<br><strong>劣势</strong>：<br>ID有<code>128 bits</code>,占用的空间较大，需要存成字符串类型，索引效率极低。<br>生成的ID中没有带<code>Timestamp</code>，无法保证趋势递增</p><ol start="3"><li>Twitter Snowflake<br>产生一个<code>long</code>型的ID，<br>使用其中<code>41bit</code>作为毫秒数，<br><code>10bit</code>作为机器编号，<br><code>12bit</code>作为毫秒内序列号。<br>这个算法单机每秒内理论上最多可以生成<code>1000*(2^12)</code>个，也就是大约<code>400W</code>的ID，完全能满足业务的需求。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在分布式系统中，经常需要使用全局唯一ID查找对应的数据。产生这种ID需要保证系统全局唯一，而且要高性能以及占用相对较少的空间。&lt;br&gt;全局唯一ID在数据库中一般会被设成主键，这样为了保证数据插入时索引的快速建立，还需要保持一个有序的趋势。&lt;br&gt;这样全局唯一ID就需要保证这</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>redis-4.常见生产问题处理</title>
    <link href="http://example.com/2020/06/15/redis-4-%E5%B8%B8%E8%A7%81%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"/>
    <id>http://example.com/2020/06/15/redis-4-%E5%B8%B8%E8%A7%81%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</id>
    <published>2020-06-15T14:36:23.000Z</published>
    <updated>2021-03-04T04:01:23.335Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-缓存和数据库双写一致性问题"><a href="#1-缓存和数据库双写一致性问题" class="headerlink" title="1.缓存和数据库双写一致性问题"></a>1.缓存和数据库双写一致性问题</h2><p>一致性问题是分布式常见问题，还可以再分为<strong>最终一致性</strong>和<strong>强一致性</strong>。数据库和缓存双写，就必然会存在不一致的问题。</p><p>首先要明白<strong>如果对数据有强一致性要求，就不能放缓存</strong>。<br>只能说降低不一致发生的概率，<strong>无法完全避免</strong>。因此，有强一致性要求的数据，不能放缓存。</p><ul><li><strong>采取正确更新策略，先更新数据库，再删缓存。</strong></li><li>其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</li></ul><h2 id="2-缓存穿透问题"><a href="#2-缓存穿透问题" class="headerlink" title="2.缓存穿透问题"></a>2.缓存穿透问题</h2><p><font color="#ff0000">缓存和数据库中都没有的数据</font>，而用户不断发起请求(也可能是故意攻击),导致数据库压力过大。</p><ul><li><strong>缓存空值</strong><br>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障）我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5分钟。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库</li><li><strong>采用布隆过滤器BloomFilter</strong><br>将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力<br>在缓存之前在加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查询缓存，缓存中没有再去查询数据库<br>优势：占用内存空间很小，位存储；性能特别高，使用key的hash判断key存不存在</li></ul><h2 id="3-缓存击穿问题"><a href="#3-缓存击穿问题" class="headerlink" title="3.缓存击穿问题"></a>3.缓存击穿问题</h2><p><font color="#ff0000">缓存中没有但数据库中有的数据</font>（一般是缓存时间到期），并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大</p><ul><li>利用互斥锁:    缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试,等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存</li><li>采用异步更新策略:    无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。</li><li>设置热点数据永不过期</li></ul><h2 id="4-缓存雪崩问题"><a href="#4-缓存雪崩问题" class="headerlink" title="4.缓存雪崩问题"></a>4.缓存雪崩问题</h2><p><font color="#ff0000">缓存同一时间大面积的失效</font>，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。(同时缓存击穿数量大)</p><ul><li>给缓存的失效时间，<strong>加上一个随机值</strong>，避免集体失效。</li><li>使用<strong>互斥锁</strong>，但是该方案吞吐量明显下降了。</li><li><strong>双缓存</strong>。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。</li><li><strong>服务降级</strong>。非核心数据先返回空如商品图片</li><li>业务系统中实现<strong>服务熔断或请求限流</strong>机制:业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。或者前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库(保护数据库防止宕机)</li><li>搭建高可靠集群<br>然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。</li></ul><h2 id="5-如何解决-Redis-的并发竞争-Key-问题"><a href="#5-如何解决-Redis-的并发竞争-Key-问题" class="headerlink" title="5.如何解决 Redis 的并发竞争 Key 问题"></a>5.如何解决 Redis 的并发竞争 Key 问题</h2><p>Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。<br>Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。</p><p>可以利用 Redis 事务机制,但是不好,因为在生产环境，基本都是 Redis 集群环境，做了数据分片操作。<br>你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。<br><strong>正确:</strong></p><ul><li>如果对这个 Key 操作，不要求顺序</li></ul><p><strong>利用setnx实现分布式锁</strong>，抢到锁就做 set 操作即可。</p><ul><li>如果对这个 Key 操作，要求顺序<br>假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。<br>期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。<br>假设时间戳如下：系统A key 1 {valueA 3:00}    系统B key 1 {valueB 3:05}    系统C key 1 {valueC 3:10}<br>假设系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。</li><li><strong>利用队列，将 set 方法变成串行访问</strong></li><li><strong>客户端角度</strong>:证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。</li></ul><h2 id="6-key是如何寻址的"><a href="#6-key是如何寻址的" class="headerlink" title="6.key是如何寻址的"></a>6.key是如何寻址的</h2><p><strong>背景:</strong><br>（1）redis 中的每一个数据库，都由一个 redisDb 的结构存储。其中：<br>redisDb.id 存储着 redis 数据库以整数表示的号码。<br>redisDb.dict 存储着该库所有的键值对数据。<br>redisDb.expires 保存着每一个键的过期时间。<br>（2）当 redis 服务器初始化时，会预先分配 16 个数据库（该数量可以通过配置文件配置），所有数据库保存到结构 redisServer 的一个成员 redisServer.db 数组中。当我们选择数据库 select number 时，程序直接通过 redisServer.db[number] 来切换数据库。有时候当程序需要知道自己是在哪个数据库时，直接读取 redisDb.id 即可。<br>（3）redis 的字典使用哈希表作为其底层实现。dict 类型使用的两个指向哈希表的指针，其中 0 号哈希表（ht[0]）主要用于存储数据库的所有键值，而 1 号哈希表主要用于程序对 0 号哈希表进行 rehash 时使用，rehash 一般是在添加新值时会触发，这里不做过多的赘述。所以 redis 中查找一个 key，其实就是对进行该 dict 结构中的 ht[0] 进行查找操作。<br>（4）既然是哈希，那么我们知道就会有哈希碰撞，那么当多个键哈希之后为同一个值怎么办呢？redis 采取链表的方式来存储多个哈希碰撞的键。也就是说，当根据 key 的哈希值找到该列表后，如果列表的长度大于 1，那么我们需要遍历该链表来找到我们所查找的 key。当然，一般情况下链表长度都为是 1，所以时间复杂度可看作 o(1)。</p><p><strong>寻址 key 的步骤</strong><br>当拿到一个 key 后，redis 先判断当前库的 0 号哈希表是否为空，即：if (dict-&gt;ht[0].size == 0)。如果为 true 直接返回 NULL。<br>判断该 0 号哈希表是否需要 rehash，因为如果在进行 rehash，那么两个表中者有可能存储该 key。如果正在进行 rehash，将调用一次_dictRehashStep 方法，_dictRehashStep 用于对数据库字典、以及哈希键的字典进行被动 rehash，这里不作赘述。<br>计算哈希表，根据当前字典与 key 进行哈希值的计算。<br>根据哈希值与当前字典计算哈希表的索引值。<br>根据索引值在哈希表中取出链表，遍历该链表找到 key 的位置。一般情况，该链表长度为 1。<br>当 ht[0] 查找完了之后，再进行了次 rehash 判断，如果未在 rehashing，则直接结束，否则对 ht[1]重复 345 步骤。</p><h2 id="7-Redis-的过期策略以及内存淘汰机制"><a href="#7-Redis-的过期策略以及内存淘汰机制" class="headerlink" title="7.Redis 的过期策略以及内存淘汰机制"></a>7.Redis 的过期策略以及内存淘汰机制</h2><p>比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？<br>还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?</p><ul><li><strong>Redis 采用的是定期删除+惰性删除策略。</strong></li></ul><h3 id="7-1为什么不用定时删除策略"><a href="#7-1为什么不用定时删除策略" class="headerlink" title="7.1为什么不用定时删除策略?"></a>7.1为什么不用定时删除策略?</h3><p>定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分<br>在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。<strong>消耗 CPU 资源。</strong></p><h3 id="7-2定期删除-惰性删除是如何工作"><a href="#7-2定期删除-惰性删除是如何工作" class="headerlink" title="7.2定期删除+惰性删除是如何工作"></a>7.2定期删除+惰性删除是如何工作</h3><p><strong>定期删除</strong>:    Redis 默认每个 100ms 检查，是否有过期的 Key，有过期 Key 则删除。<br>需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查(如果每隔 100ms，全部 Key 进行检查，Redis 岂不是卡死)。<br>因此，如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。<br><strong>惰性删除</strong>:    也就是说在你获取某个 Key 的时候，Redis 会检查一下，这个 Key 如果设置了过期时间，过期了此时就会删除。</p><h3 id="7-3采用定期删除-惰性删除就没其他问题了么"><a href="#7-3采用定期删除-惰性删除就没其他问题了么" class="headerlink" title="7.3采用定期删除+惰性删除就没其他问题了么?"></a>7.3采用定期删除+惰性删除就没其他问题了么?</h3><p>不是的，如果定期删除没删除 Key。然后你也没即时去请求 Key，也就是说惰性删除也没生效。这样，Redis的内存会越来越高。那么就应该采用<strong>内存淘汰机制</strong>。<br>在 redis.conf 中有一行配置：<br><code>maxmemory-policy volatile-lru</code></p><p>该配置就是配内存淘汰策略的：</p><h3 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h3><p>◆<code>noeviction</code>：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。<br>◆<code>allkeys-lru</code>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。<br>◆<code>allkeys-random</code>：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。<br>◆<code>volatile-lru</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。<br>◆<code>volatile-random</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。<br>◆<code>volatile-ttl</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。<br>◆<code>volatile-lfu</code><br>PS：如果没有设置 expire 的 Key，不满足先决条件(prerequisites)；那么<code>volatile-lru，volatile-random</code>和 <code>volatile-ttl</code> 策略的行为，和 noeviction(不删除) 基本上一致。</p><h2 id="8-缓存污染"><a href="#8-缓存污染" class="headerlink" title="8.缓存污染"></a>8.缓存污染</h2><p>缓存污染问题指的是留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。<br>识别出这些只访问一次或是访问次数很少的数据，在淘汰数据时，优先把它们筛选出来并淘汰掉<br>LRU 策略时，由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出来。<br>而 LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据，再筛选并淘汰访问时间最久远的数据。<br>LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用。</p><h2 id="9-Redis如何做内存优化"><a href="#9-Redis如何做内存优化" class="headerlink" title="9. Redis如何做内存优化"></a>9. Redis如何做内存优化</h2><p>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。<br>比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。</p><h2 id="10-Redis回收进程如何工作的"><a href="#10-Redis回收进程如何工作的" class="headerlink" title="10. Redis回收进程如何工作的"></a>10. Redis回收进程如何工作的</h2><p>一个客户端运行了新的命令，添加了新的数据。<br>Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。<br>一个新的命令被执行，等等。<br>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。<br>如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。</p><h2 id="11-Redis集群方案应该怎么做？都有哪些方案？"><a href="#11-Redis集群方案应该怎么做？都有哪些方案？" class="headerlink" title="11. Redis集群方案应该怎么做？都有哪些方案？"></a>11. Redis集群方案应该怎么做？都有哪些方案？</h2><p>1.codis。<br>目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。<br>2.redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。<br>3.在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-缓存和数据库双写一致性问题&quot;&gt;&lt;a href=&quot;#1-缓存和数据库双写一致性问题&quot; class=&quot;headerlink&quot; title=&quot;1.缓存和数据库双写一致性问题&quot;&gt;&lt;/a&gt;1.缓存和数据库双写一致性问题&lt;/h2&gt;&lt;p&gt;一致性问题是分布式常见问题，还可以再</summary>
      
    
    
    
    <category term="正经事" scheme="http://example.com/categories/%E6%AD%A3%E7%BB%8F%E4%BA%8B/"/>
    
    
    <category term="redis" scheme="http://example.com/tags/redis/"/>
    
  </entry>
  
</feed>
